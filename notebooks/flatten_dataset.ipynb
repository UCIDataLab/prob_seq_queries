{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab5fc0db-8671-45eb-9006-8236cda57d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "import glob\n",
    "import torch\n",
    "\n",
    "sys.path.insert(1,\"/home/showalte/research/prob_seq_queries/\")\n",
    "from seq_queries.utils import read_pkl, write_pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae87bf22-bcf6-49ea-b43c-9c6bd34216f9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Estimate fields\n",
    "- ground_truth/beam_search_lb\n",
    "- Importance sampling estimate\n",
    "- Hybrid estimate\n",
    "- Importance sampling variance\n",
    "- Hybrid variance\n",
    "\n",
    "# General Metadata\n",
    "- dataset_name\n",
    "- experiment_name\n",
    "- history_id\n",
    "- Excluded term\n",
    "- sequence_length\n",
    "- history_length\n",
    "- total_sequence_length\n",
    "\n",
    "# Sampling metadata\n",
    "- num_mc_samples (sub_estimates)\n",
    "- sample_model_iters\n",
    "\n",
    "# Hybrid data\n",
    "- hybrid_model_iters\n",
    "\n",
    "# Beam search metadata\n",
    "- min_variance\n",
    "- search_model_iters\n",
    "- min_variance_reduction\n",
    "- true_coverage\n",
    "- restricted_coverage\n",
    "- num_beams\n",
    "- top_k\n",
    "- top_p\n",
    "- (beam search) interpolation_func\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b52721a-1c0f-4001-b451-3899e8e6176e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_experiment_data(experiment, dataset, h, s, root=\"../data\", \n",
    "#             methods=['beam_search_is_hybrid','importance_sampling','random_sampling','beam_search'],\n",
    "#             gt_methods=['ground_truth','beam_search']):\n",
    "    \n",
    "#         data_dict = {}\n",
    "#         gt_type=None\n",
    "#         for method in methods:\n",
    "#             template_path=root + f\"/{method}/{dataset}/{experiment}/\"\n",
    "#             template_file=(f\"{experiment.replace('_','-')}_{dataset.replace('_','-')}_\" +\n",
    "#             f\"{method.replace('_','-')}_{h}h_{s}s*mc.pkl\")\n",
    "#             pot_pattern = os.path.join(template_path,template_file)\n",
    "#             pot_paths = glob.glob(pot_pattern)\n",
    "#             assert len(pot_paths) == 1,\\\n",
    "#                 f\"Found {len(pot_paths)} paths for {pot_pattern}\"\n",
    "#             print(method, pot_paths[0])\n",
    "#             data_dict[method]= read_pkl(pot_paths[0])\n",
    "#             data_dict[method]['metadata']['result_filepath'] = pot_paths[0]\n",
    "#         for gt_method in gt_methods:\n",
    "#             try:\n",
    "#                 template_path=root + f\"/{gt_method}/{dataset}/{experiment}/\"\n",
    "#                 # Don't match on model budget terms\n",
    "#                 template_file=(f\"{experiment.replace('_','-')}_{dataset.replace('_','-')}_\" +\n",
    "#                                f\"{gt_method.replace('_','-')}_{h}h_{s}s*[!t].pkl\")\n",
    "#                 pot_pattern = os.path.join(template_path,template_file)\n",
    "#                 pot_paths = glob.glob(pot_pattern)\n",
    "#                 assert len(pot_paths) == 1,\\\n",
    "#                     f\"Found {len(pot_paths)} paths for {pot_pattern}\"\n",
    "#                 print(\"GT: \", gt_method, \"\\n\",pot_paths[0],\"\\n=============\")\n",
    "#                 data_dict[gt_method]= read_pkl(pot_paths[0])\n",
    "#                 data_dict[gt_method]['metadata']['result_filepath'] = pot_paths[0]\n",
    "#                 data_dict['gt_type'] = gt_method\n",
    "#                 return data_dict\n",
    "#             except: pass\n",
    "#         assert False,\"Could not find ground truth\"\n",
    "#         print()\n",
    "#         return None\n",
    "    \n",
    "def get_experiment_data_model_budget(experiment, dataset, h, s, root=\"../data\", \n",
    "            methods=['beam_search_is_hybrid','importance_sampling','random_sampling','beam_search'],\n",
    "            gt_methods=['ground_truth','beam_search']):\n",
    "    \n",
    "        data_dict = {}\n",
    "        gt_type=None\n",
    "        for method in methods:\n",
    "            template_path=root + f\"/{method}/{dataset}/{experiment}/\"\n",
    "            template_file=(f\"{experiment.replace('_','-')}_{dataset.replace('_','-')}_\"\n",
    "            + f\"{method.replace('_','-')}_{h}h_{s}s*{'' if method == 'beam_search_is_hybrid' else 'model-budget'}.pkl\")\n",
    "            pot_pattern = os.path.join(template_path,template_file)\n",
    "            pot_paths = glob.glob(pot_pattern)\n",
    "            assert len(pot_paths) == 1,\\\n",
    "                f\"Found {len(pot_paths)} paths for {pot_pattern}\"\n",
    "            # print(method,pot_paths[0])\n",
    "            print(method, \"\\n\",pot_paths[0],\"\\n=============\")\n",
    "            data_dict[method]= read_pkl(pot_paths[0])\n",
    "            data_dict[method]['metadata']['result_filepath'] = pot_paths[0]\n",
    "        for gt_method in gt_methods:\n",
    "            try:\n",
    "                template_path=root + f\"/{gt_method}/{dataset}/{experiment}/\"\n",
    "                template_file=(f\"{experiment.replace('_','-')}_{dataset.replace('_','-')}_\" +\n",
    "                               f\"{gt_method.replace('_','-')}_{h}h_{s}s*.pkl\")\n",
    "                pot_pattern = os.path.join(template_path,template_file)\n",
    "                pot_paths = glob.glob(pot_pattern)\n",
    "                assert len(pot_paths) == 1,\\\n",
    "                    f\"Found {len(pot_paths)} paths for {pot_pattern}\"\n",
    "                print(\"GT: \", gt_method, \"\\n\",pot_paths[0],\"\\n=============\")\n",
    "                data_dict[gt_method]= read_pkl(pot_paths[0])\n",
    "                data_dict[gt_method]['metadata']['result_filepath'] = pot_paths[0]\n",
    "                data_dict['gt_type'] = gt_method\n",
    "                return data_dict\n",
    "            except: pass\n",
    "        assert False,\"Could not find ground truth\"\n",
    "        return None\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bff8c61a-43ae-4901-8cf0-1f34078701f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_search(samp_dict,sub_estimates,search_type=\"beam_search\"):\n",
    "    samp_estimates = samp_dict['bs_lower_bound'][:,:len(sub_estimates)]\n",
    "    if not sub_estimates:\n",
    "        if len(samp_estimates.shape) ==3:\n",
    "            samp_estimates = torch.gather(samp_estimates.mean(dim=1),1,\n",
    "                                          samp_dict['excluded_terms'].unsqueeze(-1)).squeeze()\n",
    "            assert len(samp_estimates.shape) == 1,f\"Shape of bs_lower_bounds is {len(samp_estimates.shape)}\"\n",
    "        if len(samp_estimates.shape) ==2:\n",
    "            samp_estimates = torch.gather(samp_estimates,1,\n",
    "                                              samp_dict['excluded_terms'].unsqueeze(-1)).squeeze()\n",
    "        \n",
    "        df = pd.DataFrame(samp_estimates)\n",
    "        df[f'{sample_type}_model_iters'] = samp_dict['model_iters']\n",
    "        df[f'{sample_type}_num_beams'] = samp_dist['sample_estimate_var']\n",
    "        \n",
    "    else:\n",
    "        assert samp_estimates.shape[1] == len(sub_estimates),\\\n",
    "        (\"Importance sampling estimates and sub_estimates are not aligned in shape.\" +\n",
    "         f\"got sample_est: {samp_estimates.shape[1]} and sub_estimates: {len(sub_estimates)}\")\n",
    "        if len(samp_estimates.shape) == 2:\n",
    "            samp_estimates = pd.DataFrame(samp_estimates,columns=sub_estimates)\n",
    "            beams = pd.DataFrame(samp_dict['num_beams'][:,:len(sub_estimates)],columns=sub_estimates)\n",
    "            true_cov = pd.DataFrame(samp_dict['true_coverage'][:,:len(sub_estimates)],columns=sub_estimates)\n",
    "            restr_cov = pd.DataFrame(samp_dict['restricted_coverage'][:,:len(sub_estimates)],columns=sub_estimates)\n",
    "            model_iters = pd.DataFrame(samp_dict['model_iters'][:,:len(sub_estimates)],columns=sub_estimates)\n",
    "            \n",
    "            df_list = [\n",
    "                (f'{search_type}_lb',samp_estimates),\n",
    "                ('model_iters',model_iters),\n",
    "                ('num_beams',beams),\n",
    "                ('true_coverage',true_cov),\n",
    "                ('restricted_coverage',restr_cov),\n",
    "            ]\n",
    "            \n",
    "            for i,(name,df) in enumerate(df_list):\n",
    "                df = pd.melt(df,value_vars=sub_estimates)\n",
    "                df.columns = ['num_samples',name]\n",
    "            df = df_list[0]\n",
    "            for name,df in df_list[1:]:\n",
    "                df[f'{search_type}_{name}']=df[name]\n",
    "            \n",
    "            # df[f'{sample_type}_variance']=var_df['variance']\n",
    "            \n",
    "        elif len(samp_estimates.shape) == 3:\n",
    "            df_list = []\n",
    "            for i in range(len(sub_estimates)):\n",
    "                df = pd.DataFrame(\n",
    "                            torch.gather(samp_estimates[:,i],1,\n",
    "                                      samp_dict['excluded_terms'].unsqueeze(-1)).squeeze()\n",
    "                        )\n",
    "                df[f'{search_type}_model_iters'] = samp_dict['model_iters'][:,i]\n",
    "                df[f'{search_type}_num_beams'] = samp_dict['num_beams'][:,i]\n",
    "                df[f'{search_type}_true_coverage'] = samp_dict['true_coverage'][:,i]\n",
    "                df[f'{search_type}_restricted_coverage'] = samp_dict['restricted_coverage'][:,i]\n",
    "                df_list.append(df)\n",
    "            df = pd.concat(df_list,axis=0,ignore_index=True)\n",
    "        else:\n",
    "            assert False,f\"Shape of samp_estimates is {len(samp_estimates.shape)}\"\n",
    "    res_cols = ['lb','model_iters','num_beams','true_coverage','restricted_coverage']\n",
    "    assert df.shape[-1] == len(res_cols), f\"DF shape is {df.shape}\"\n",
    "    df.columns = [f'{search_type}_{s}' for s in res_cols]\n",
    "    df['gt_type'] = 'ground_truth' if search_type=='ground_truth' else 'beam_search'\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def flatten_sampling(samp_dict,sub_estimates,sample_type=\"importance\"):\n",
    "    samp_estimates = samp_dict['sample_estimates'][:,:len(sub_estimates)]\n",
    "    if not sub_estimates:\n",
    "        if len(samp_estimates.shape) ==3:\n",
    "            assert samp_estimates.shape[1] == samp_dict['metadata']['num_mc_samples'],\\\n",
    "            (f\"Error, estimate dimensions are {samp_estimates.shape} but the number of samples is \" +\n",
    "             f\"{samp_dict['metadata']['num_mc_samples']}, which does not match\")\n",
    "            \n",
    "            samp_estimates = torch.gather(samp_estimates.mean(dim=1),1,\n",
    "                                          samp_dict['excluded_terms'].unsqueeze(-1)).squeeze()\n",
    "            assert len(samp_estimates.shape) == 1,f\"Shape of imp_samp_estimates is {len(samp_estimates.shape)}\"\n",
    "        if len(samp_estimates.shape) ==2:\n",
    "            samp_estimates = torch.gather(samp_estimates,1,\n",
    "                                              samp_dict['excluded_terms'].unsqueeze(-1)).squeeze()\n",
    "        \n",
    "        df = pd.DataFrame(samp_estimates)\n",
    "        df.insert(0,'num_mc_samples',samp_dict['metadata']['num_mc_samples'])\n",
    "        df[f'{sample_type}_model_iters'] = samp_dict['model_iters']\n",
    "        df[f'{sample_type}_est_variance'] = samp_dist['sample_estimate_var']\n",
    "        \n",
    "    else:\n",
    "        assert samp_estimates.shape[1] == len(sub_estimates),\\\n",
    "        (\"Importance sampling estimates and sub_estimates are not aligned in shape.\" +\n",
    "         f\"got sample_est: {samp_estimates.shape[1]} and sub_estimates: {len(sub_estimates)}\")\n",
    "        if len(samp_estimates.shape) == 2:\n",
    "            samp_estimates = pd.DataFrame(samp_estimates,columns=sub_estimates)\n",
    "            samp_var = pd.DataFrame(samp_dict['sample_estimate_var'][:,:len(sub_estimates)],columns=sub_estimates)\n",
    "            model_iters = pd.DataFrame(samp_dict['model_iters'][:,:len(sub_estimates)],columns=sub_estimates)\n",
    "            sub_estimate_num_samples = None\n",
    "            if sample_type != 'hybrid':\n",
    "                sub_estimate_num_samples = pd.DataFrame(samp_dict['num_mc_samples'][:,:len(sub_estimates)],columns=sub_estimates)\n",
    "            \n",
    "            df_list = [\n",
    "                (f'{sample_type}_sampling_est',samp_estimates),\n",
    "                ('num_mc_samples',sub_estimate_num_samples),\n",
    "                ('model_iters',model_iters),\n",
    "                ('variance',samp_var),\n",
    "            ]\n",
    "            \n",
    "            for i,(name,df) in enumerate(df_list):\n",
    "                if name == 'num_mc_samples' and sample_type==\"hybrid\": continue\n",
    "                df = pd.melt(df,value_vars=sub_estimates)\n",
    "                df.columns = ['num_samples',name]\n",
    "            df = df_list[0]\n",
    "            for name,df in df_list[1:]:\n",
    "                if name == 'num_mc_samples' and sample_type==\"hybrid\": continue\n",
    "                df[f'{sample_type}_{name}']=df[name]\n",
    "            if df_type == \"hybrid\":\n",
    "                df['num_mc_samples'] = df['num_samples']\n",
    "                df = df[['num_mc_samples',f'{sample_type}_sampling_est',\n",
    "                         'model_iters','variance']]\n",
    "            \n",
    "            # df[f'{sample_type}_variance']=var_df['variance']\n",
    "            \n",
    "        elif len(samp_estimates.shape) == 3:\n",
    "            df_list = []\n",
    "            for i in range(len(sub_estimates)):\n",
    "                df = pd.DataFrame(\n",
    "                            torch.gather(samp_estimates[:,i],1,\n",
    "                                      samp_dict['excluded_terms'].unsqueeze(-1)).squeeze()\n",
    "                        )\n",
    "                if sample_type == \"hybrid\": df.insert(0,'num_mc_samples',sub_estimates[i])\n",
    "                else: df.insert(0,'num_mc_samples',samp_dict['num_mc_samples'][:,i])\n",
    "                df[f'{sample_type}_model_iters'] = samp_dict['model_iters'][:,i]\n",
    "                samp_est_var = torch.gather(samp_dict['sample_estimate_var'][:,i],1,\n",
    "                                            samp_dict['excluded_terms'].unsqueeze(-1)).squeeze()\n",
    "                                            \n",
    "                df[f'{sample_type}_variance'] = samp_est_var\n",
    "                \n",
    "                df_list.append(df)\n",
    "            df = pd.concat(df_list,axis=0,ignore_index=True)\n",
    "        else:\n",
    "            assert False,f\"Shape of samp_estimates is {len(samp_estimates.shape)}\"\n",
    "    res_cols = ['num_mc_samples','sampling_est','model_iters','variance']\n",
    "    assert df.shape[-1] == len(res_cols), f\"DF shape is {df.shape}\"\n",
    "    df.columns = [f'{sample_type}_{s}' for s in res_cols]\n",
    "    return df\n",
    "\n",
    "\n",
    "def flatten_gt(data_dict,gt_type):\n",
    "    gt_dict = data_dict[gt_type]\n",
    "    print(gt_dict.keys())\n",
    "    # gt = gt_dict['bs_lower_bound']\n",
    "    gt = torch.gather(gt_dict['bs_lower_bound'],1,\n",
    "                      gt_dict['excluded_terms'].unsqueeze(-1)).squeeze()\n",
    "    assert len(gt.shape) == 1,\\\n",
    "    f\"Ground truth has {len(gt.shape)} dimensions\"\n",
    "    df = pd.DataFrame(gt,columns=['ground_truth'])\n",
    "    for item in ['true_coverage','restricted_coverage','model_iters']:\n",
    "        df[f\"gt_{item}\"] = [gti.item() for gti in gt_dict[item]]\n",
    "    # df[\"gt_model_iters\"] = gt_dict['model_iters']\n",
    "    df['gt_type'] = gt_type\n",
    "    df['gt_num_beams'] = gt_dict['metadata']['num_beams']\n",
    "    \n",
    "    return df\n",
    "    \n",
    "\n",
    "def flatten_experiment(data_dict,experiment, dataset,h,s,\n",
    "     global_agreement_vals= ['excluded_terms']):\n",
    "    sub_estimates = sorted(list(\n",
    "        # set(data_dict['importance_sampling']['metadata']['sub_estimates']) &\n",
    "        # set(data_dict['random_sampling']['metadata']['sub_estimates']) &\n",
    "        set(data_dict['beam_search_is_hybrid']['metadata']['sub_estimates'])))\n",
    "    sub_est_len = 1 if not sub_estimates else len(sub_estimates)\n",
    "    \n",
    "    importance_df = flatten_sampling(data_dict['importance_sampling'],sub_estimates,sample_type ='importance')\n",
    "    random_df = flatten_sampling(data_dict['random_sampling'],sub_estimates,sample_type ='random')\n",
    "    hybrid_df = flatten_sampling(data_dict['beam_search_is_hybrid'],sub_estimates,sample_type ='hybrid')\n",
    "    search_df = flatten_search(data_dict['beam_search'],sub_estimates,search_type='beam_search')\n",
    "    # hybrid_df.drop(\"num_mc_samples\",inplace = True,axis=1)\n",
    "    \n",
    "    gt_df = flatten_gt(data_dict,data_dict['gt_type'])\n",
    "    gt_df = pd.concat([gt_df]*sub_est_len,axis=0,ignore_index=True)\n",
    "    final_df = pd.concat([random_df,importance_df,hybrid_df,search_df,gt_df],axis=1)\n",
    "    \n",
    "    # Metadata checks\n",
    "    is_metadata = ['top_k','top_p']\n",
    "    hybrid_metadata = ['min_variance','min_var_reduction']\n",
    "    bs_metadata = []\n",
    "    gt_metadata = []\n",
    "    for m in is_metadata:\n",
    "        final_df['is_' + m] = data_dict['importance_sampling']['metadata'][m]\n",
    "    for m in hybrid_metadata:\n",
    "        final_df['hybrid_' + m] = data_dict['beam_search_is_hybrid']['metadata'][m]\n",
    "    for m in bs_metadata:\n",
    "        final_df['bs_lb_' + m] = data_dict['beam_search']['metadata'][m]\n",
    "    for m in bs_metadata:\n",
    "        final_df['gt_' + m] = data_dict[data_dict['gt_type']]['metadata'][m]\n",
    "    final_df['interp_func'] = str(data_dict[data_dict['gt_type']]['metadata']['interp_func']).split(\" \")[1]\n",
    "    \n",
    "    \n",
    "    final_df['dataset_name'] = dataset\n",
    "    final_df['hist_len'] = h\n",
    "    final_df['total_seq_len'] = s\n",
    "    final_df['seq_len'] = s-h\n",
    "    sequence_ids = list(range(data_dict['importance_sampling']['sample_estimates'].shape[0]))*sub_est_len\n",
    "    excluded_terms = data_dict['importance_sampling']['excluded_terms'].numpy().tolist()*sub_est_len\n",
    "    final_df['sequence_id'] = sequence_ids\n",
    "    final_df['excluded_term'] = excluded_terms\n",
    "                 \n",
    "    # ==== Phase shift stuff ====\n",
    "    # phase_shifts = read_pkl(\"/srv/disk00/samshow/amazon/amazon_phase_trans.pkl\")\n",
    "    # phase_shift_val_inds = read_pkl(\"../data/amazon/amazon_val_dl_transition_inds.pkl\")\n",
    "    # phase_shifts = phase_shifts[phase_shift_val_inds].numpy().tolist()\n",
    "    # print(phase_shift_val_inds.shape, final_df.shape)\n",
    "    # final_df['phase_shifts'] = phase_shifts * sub_est_len\n",
    "    # final_df['phase_shifts'] -=1\n",
    "    \n",
    "    return final_df\n",
    "     \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb936c89-eb0e-42cd-923b-8a60a9fc167c",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = [\"val_dl\"]\n",
    "dataset = [\"apps\"]\n",
    "lengths = [(13,15),(12,15)]\n",
    "def flatten_experiments(experiments, datasets, lengths,model_budget=False):\n",
    "    data_list = []\n",
    "    for experiment in experiments:\n",
    "        for dataset in datasets:\n",
    "            for h,s in lengths:\n",
    "                # try:\n",
    "                    \n",
    "                    if model_budget:\n",
    "                        data = get_experiment_data(experiment,dataset,h,s)\n",
    "                    else:\n",
    "                        data = get_experiment_data_model_budget(experiment,dataset,h,s)\n",
    "                        \n",
    "                    df = flatten_experiment(data,experiment, dataset, h,s)\n",
    "                    \n",
    "#                     print(df.head())\n",
    "#                     print(df.columns)\n",
    "#                     print(df.shape)\n",
    "#                     sys.exit(1)\n",
    "                    \n",
    "                    data_list.append(df)\n",
    "                    \n",
    "    # print(len(data_list))\n",
    "    data_df = pd.concat(data_list,axis = 0)\n",
    "    ordering = [ 'dataset_name','sequence_id','seq_len', 'excluded_term', 'gt_type','ground_truth',\n",
    "                'random_sampling_est','importance_sampling_est','hybrid_sampling_est', 'beam_search_lb',\n",
    "                'random_num_mc_samples', 'importance_num_mc_samples','hybrid_num_mc_samples',\n",
    "                'gt_model_iters','random_model_iters', #continues to next line\n",
    "                'importance_model_iters','hybrid_model_iters','beam_search_model_iters',\n",
    "                'random_variance','importance_variance',  'hybrid_variance',\n",
    "                'gt_true_coverage', 'gt_restricted_coverage', 'gt_num_beams',\n",
    "                'beam_search_true_coverage', 'beam_search_restricted_coverage', 'beam_search_num_beams',\n",
    "                'is_top_k','is_top_p',\n",
    "                'hybrid_min_variance','hybrid_min_var_reduction', \n",
    "                'interp_func','hist_len', 'total_seq_len']#, 'phase_shifts']\n",
    "    data_df = data_df[ordering]\n",
    "    print(data_df.columns)\n",
    "    \n",
    "    return data_df\n",
    "                \n",
    "                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62c51bbf-1517-42cc-8ed2-b99b496d041f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beam_search_is_hybrid \n",
      " ../data/beam_search_is_hybrid/moocs/val_dl/val-dl_moocs_beam-search-is-hybrid_13h_15s_1000mc.pkl \n",
      "=============\n",
      "importance_sampling \n",
      " ../data/importance_sampling/moocs/val_dl/val-dl_moocs_importance-sampling_13h_15s_1000mc_model-budget.pkl \n",
      "=============\n",
      "random_sampling \n",
      " ../data/random_sampling/moocs/val_dl/val-dl_moocs_random-sampling_13h_15s_1000mc_model-budget.pkl \n",
      "=============\n",
      "beam_search \n",
      " ../data/beam_search/moocs/val_dl/val-dl_moocs_beam-search_13h_15s_model-budget.pkl \n",
      "=============\n",
      "GT:  ground_truth \n",
      " ../data/ground_truth/moocs/val_dl/val-dl_moocs_ground-truth_13h_15s.pkl \n",
      "=============\n",
      "dict_keys(['true_coverage', 'restricted_coverage', 'num_beams', 'model_iters', 'bs_lower_bound', 'intermediate_lbs', 'metadata', 'excluded_terms'])\n",
      "beam_search_is_hybrid \n",
      " ../data/beam_search_is_hybrid/moocs/val_dl/val-dl_moocs_beam-search-is-hybrid_12h_15s_1000mc.pkl \n",
      "=============\n",
      "importance_sampling \n",
      " ../data/importance_sampling/moocs/val_dl/val-dl_moocs_importance-sampling_12h_15s_1000mc_model-budget.pkl \n",
      "=============\n",
      "random_sampling \n",
      " ../data/random_sampling/moocs/val_dl/val-dl_moocs_random-sampling_12h_15s_1000mc_model-budget.pkl \n",
      "=============\n",
      "beam_search \n",
      " ../data/beam_search/moocs/val_dl/val-dl_moocs_beam-search_12h_15s_model-budget.pkl \n",
      "=============\n",
      "GT:  ground_truth \n",
      " ../data/ground_truth/moocs/val_dl/val-dl_moocs_ground-truth_12h_15s.pkl \n",
      "=============\n",
      "dict_keys(['true_coverage', 'restricted_coverage', 'num_beams', 'model_iters', 'bs_lower_bound', 'intermediate_lbs', 'metadata', 'excluded_terms'])\n",
      "Index(['dataset_name', 'sequence_id', 'seq_len', 'excluded_term', 'gt_type',\n",
      "       'gt_type', 'ground_truth', 'random_sampling_est',\n",
      "       'importance_sampling_est', 'hybrid_sampling_est', 'beam_search_lb',\n",
      "       'random_num_mc_samples', 'importance_num_mc_samples',\n",
      "       'hybrid_num_mc_samples', 'gt_model_iters', 'random_model_iters',\n",
      "       'importance_model_iters', 'hybrid_model_iters',\n",
      "       'beam_search_model_iters', 'random_variance', 'importance_variance',\n",
      "       'hybrid_variance', 'gt_true_coverage', 'gt_restricted_coverage',\n",
      "       'gt_num_beams', 'beam_search_true_coverage',\n",
      "       'beam_search_restricted_coverage', 'beam_search_num_beams', 'is_top_k',\n",
      "       'is_top_p', 'hybrid_min_variance', 'hybrid_min_var_reduction',\n",
      "       'interp_func', 'hist_len', 'total_seq_len'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = flatten_experiments(['val_dl'],['moocs'],[(13,15),(12,15)])\n",
    "# df1 = flatten_experiments(['val_dl'],['shakespeare'],[(18,20),(17,20)])\n",
    "# df2 = flatten_experiments(['val_dl'],['apps'],[(13,15),(12,15)])\n",
    "# df3 = flatten_experiments(['val_dl'],['amazon'],[(13,15),(12,15)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9686d012-ca67-4160-aace-cabe4dc2d6dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ce843b1-19fd-4a08-bd5e-a76576456916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance_model_iters</th>\n",
       "      <th>hybrid_model_iters</th>\n",
       "      <th>beam_search_model_iters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10909</th>\n",
       "      <td>2019</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10910</th>\n",
       "      <td>2964</td>\n",
       "      <td>2963</td>\n",
       "      <td>2965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10911</th>\n",
       "      <td>2919</td>\n",
       "      <td>2919</td>\n",
       "      <td>2919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10912</th>\n",
       "      <td>2628</td>\n",
       "      <td>2628</td>\n",
       "      <td>2629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10913</th>\n",
       "      <td>2976</td>\n",
       "      <td>2975</td>\n",
       "      <td>2977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10914</th>\n",
       "      <td>3000</td>\n",
       "      <td>2998</td>\n",
       "      <td>3001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10915</th>\n",
       "      <td>2730</td>\n",
       "      <td>2730</td>\n",
       "      <td>2731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10916</th>\n",
       "      <td>2922</td>\n",
       "      <td>2922</td>\n",
       "      <td>2923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10917</th>\n",
       "      <td>2565</td>\n",
       "      <td>2564</td>\n",
       "      <td>2565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10918</th>\n",
       "      <td>2046</td>\n",
       "      <td>2045</td>\n",
       "      <td>2047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10919</th>\n",
       "      <td>2985</td>\n",
       "      <td>2985</td>\n",
       "      <td>2985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10920</th>\n",
       "      <td>2985</td>\n",
       "      <td>2983</td>\n",
       "      <td>2985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10921</th>\n",
       "      <td>2940</td>\n",
       "      <td>2938</td>\n",
       "      <td>2941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10922</th>\n",
       "      <td>2967</td>\n",
       "      <td>2966</td>\n",
       "      <td>2967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10923</th>\n",
       "      <td>2967</td>\n",
       "      <td>2965</td>\n",
       "      <td>2967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10924</th>\n",
       "      <td>2943</td>\n",
       "      <td>2941</td>\n",
       "      <td>2943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10925</th>\n",
       "      <td>3000</td>\n",
       "      <td>2999</td>\n",
       "      <td>3001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10926</th>\n",
       "      <td>2505</td>\n",
       "      <td>2503</td>\n",
       "      <td>2505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10927</th>\n",
       "      <td>2430</td>\n",
       "      <td>2430</td>\n",
       "      <td>2431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10928</th>\n",
       "      <td>1653</td>\n",
       "      <td>1651</td>\n",
       "      <td>1653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10929</th>\n",
       "      <td>2979</td>\n",
       "      <td>2978</td>\n",
       "      <td>2979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10930</th>\n",
       "      <td>2991</td>\n",
       "      <td>2991</td>\n",
       "      <td>2991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10931</th>\n",
       "      <td>1695</td>\n",
       "      <td>1695</td>\n",
       "      <td>1695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10932</th>\n",
       "      <td>2979</td>\n",
       "      <td>2978</td>\n",
       "      <td>2979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10933</th>\n",
       "      <td>2967</td>\n",
       "      <td>2966</td>\n",
       "      <td>2967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10934</th>\n",
       "      <td>2688</td>\n",
       "      <td>2688</td>\n",
       "      <td>2689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10935</th>\n",
       "      <td>1938</td>\n",
       "      <td>1936</td>\n",
       "      <td>1939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10936</th>\n",
       "      <td>1662</td>\n",
       "      <td>1660</td>\n",
       "      <td>1663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10937</th>\n",
       "      <td>2589</td>\n",
       "      <td>2589</td>\n",
       "      <td>2589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10938</th>\n",
       "      <td>2520</td>\n",
       "      <td>2520</td>\n",
       "      <td>2521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10939</th>\n",
       "      <td>1674</td>\n",
       "      <td>1673</td>\n",
       "      <td>1675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10940</th>\n",
       "      <td>2967</td>\n",
       "      <td>2967</td>\n",
       "      <td>2967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10941</th>\n",
       "      <td>2940</td>\n",
       "      <td>2940</td>\n",
       "      <td>2941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10942</th>\n",
       "      <td>2799</td>\n",
       "      <td>2798</td>\n",
       "      <td>2799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10943</th>\n",
       "      <td>2859</td>\n",
       "      <td>2859</td>\n",
       "      <td>2859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10944</th>\n",
       "      <td>3003</td>\n",
       "      <td>3003</td>\n",
       "      <td>3003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10945</th>\n",
       "      <td>2895</td>\n",
       "      <td>2895</td>\n",
       "      <td>2895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10946</th>\n",
       "      <td>2040</td>\n",
       "      <td>2040</td>\n",
       "      <td>2041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10947</th>\n",
       "      <td>2916</td>\n",
       "      <td>2914</td>\n",
       "      <td>2917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10948</th>\n",
       "      <td>2559</td>\n",
       "      <td>2558</td>\n",
       "      <td>2559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10949</th>\n",
       "      <td>2949</td>\n",
       "      <td>2949</td>\n",
       "      <td>2949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10950</th>\n",
       "      <td>1881</td>\n",
       "      <td>1881</td>\n",
       "      <td>1881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10951</th>\n",
       "      <td>2385</td>\n",
       "      <td>2383</td>\n",
       "      <td>2385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10952</th>\n",
       "      <td>3003</td>\n",
       "      <td>3003</td>\n",
       "      <td>3003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10953</th>\n",
       "      <td>2844</td>\n",
       "      <td>2842</td>\n",
       "      <td>2845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10954</th>\n",
       "      <td>2883</td>\n",
       "      <td>2881</td>\n",
       "      <td>2883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10955</th>\n",
       "      <td>2997</td>\n",
       "      <td>2997</td>\n",
       "      <td>2997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10956</th>\n",
       "      <td>1752</td>\n",
       "      <td>1751</td>\n",
       "      <td>1753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10957</th>\n",
       "      <td>2655</td>\n",
       "      <td>2653</td>\n",
       "      <td>2655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10958</th>\n",
       "      <td>2139</td>\n",
       "      <td>2139</td>\n",
       "      <td>2139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       importance_model_iters  hybrid_model_iters  beam_search_model_iters\n",
       "10909                    2019                2019                     2019\n",
       "10910                    2964                2963                     2965\n",
       "10911                    2919                2919                     2919\n",
       "10912                    2628                2628                     2629\n",
       "10913                    2976                2975                     2977\n",
       "10914                    3000                2998                     3001\n",
       "10915                    2730                2730                     2731\n",
       "10916                    2922                2922                     2923\n",
       "10917                    2565                2564                     2565\n",
       "10918                    2046                2045                     2047\n",
       "10919                    2985                2985                     2985\n",
       "10920                    2985                2983                     2985\n",
       "10921                    2940                2938                     2941\n",
       "10922                    2967                2966                     2967\n",
       "10923                    2967                2965                     2967\n",
       "10924                    2943                2941                     2943\n",
       "10925                    3000                2999                     3001\n",
       "10926                    2505                2503                     2505\n",
       "10927                    2430                2430                     2431\n",
       "10928                    1653                1651                     1653\n",
       "10929                    2979                2978                     2979\n",
       "10930                    2991                2991                     2991\n",
       "10931                    1695                1695                     1695\n",
       "10932                    2979                2978                     2979\n",
       "10933                    2967                2966                     2967\n",
       "10934                    2688                2688                     2689\n",
       "10935                    1938                1936                     1939\n",
       "10936                    1662                1660                     1663\n",
       "10937                    2589                2589                     2589\n",
       "10938                    2520                2520                     2521\n",
       "10939                    1674                1673                     1675\n",
       "10940                    2967                2967                     2967\n",
       "10941                    2940                2940                     2941\n",
       "10942                    2799                2798                     2799\n",
       "10943                    2859                2859                     2859\n",
       "10944                    3003                3003                     3003\n",
       "10945                    2895                2895                     2895\n",
       "10946                    2040                2040                     2041\n",
       "10947                    2916                2914                     2917\n",
       "10948                    2559                2558                     2559\n",
       "10949                    2949                2949                     2949\n",
       "10950                    1881                1881                     1881\n",
       "10951                    2385                2383                     2385\n",
       "10952                    3003                3003                     3003\n",
       "10953                    2844                2842                     2845\n",
       "10954                    2883                2881                     2883\n",
       "10955                    2997                2997                     2997\n",
       "10956                    1752                1751                     1753\n",
       "10957                    2655                2653                     2655\n",
       "10958                    2139                2139                     2139"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data['importance_sampling']['metadata']['sub_estimates']\n",
    "# print(df.shape)\n",
    "# print(df.isnull().sum())\n",
    "# df.phase_shifts.describe()\n",
    "# df[['importance_model_iters','hybrid_model_iters','beam_search_model_iters']].tail(50)\n",
    "# df[['hybrid_num_mc_samples', 'importance_num_mc_samples','beam_search_num_beams']].head(50)\n",
    "# df[['beam_search_true_coverage','beam_search_restricted_coverage','beam_search_num_beams']].tail(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81963683-e69a-4cbf-be8f-970918de1117",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15b17f57-5661-4ffc-8b42-d94827b114ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['shakespeare', 0, 2, ..., 'lin_interp', 18, 20],\n",
       "       ['shakespeare', 1, 2, ..., 'lin_interp', 18, 20],\n",
       "       ['shakespeare', 2, 2, ..., 'lin_interp', 18, 20],\n",
       "       ...,\n",
       "       ['shakespeare', 2284, 3, ..., 'lin_interp', 17, 20],\n",
       "       ['shakespeare', 2285, 3, ..., 'lin_interp', 17, 20],\n",
       "       ['shakespeare', 2286, 3, ..., 'lin_interp', 17, 20]], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b010b1e-e070-4f9b-85bf-141fd935acab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'importance')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df = df[df['phase_shifts'] > 10]\n",
    "plt.scatter(df['ground_truth'],df['hybrid_sampling_est'])\n",
    "plt.title(\"importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a3e8a10-b1b5-4498-bc4a-90eaa5ecbba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance_est_variance</th>\n",
       "      <th>hybrid_est_variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.191800e+04</td>\n",
       "      <td>2.191800e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.688037e-05</td>\n",
       "      <td>3.907905e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.492985e-04</td>\n",
       "      <td>8.797111e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.860333e-20</td>\n",
       "      <td>1.116206e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.422974e-09</td>\n",
       "      <td>1.191007e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.011587e-08</td>\n",
       "      <td>1.700204e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.072154e-07</td>\n",
       "      <td>1.139661e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.445925e-02</td>\n",
       "      <td>4.038442e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       importance_est_variance  hybrid_est_variance\n",
       "count             2.191800e+04         2.191800e+04\n",
       "mean              3.688037e-05         3.907905e-06\n",
       "std               6.492985e-04         8.797111e-05\n",
       "min               2.860333e-20         1.116206e-19\n",
       "25%               4.422974e-09         1.191007e-09\n",
       "50%               4.011587e-08         1.700204e-08\n",
       "75%               3.072154e-07         1.139661e-07\n",
       "max               4.445925e-02         4.038442e-03"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['importance_est_variance','hybrid_est_variance']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ed16f5a-8501-46b6-8e3e-3d4f3a55b259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset_name               0\n",
       "sequence_id                0\n",
       "seq_len                    0\n",
       "excluded_term              0\n",
       "gt_type                    0\n",
       "ground_truth               0\n",
       "importance_sampling_est    0\n",
       "hybrid_sampling_est        0\n",
       "num_mc_samples             0\n",
       "importance_model_iters     0\n",
       "hybrid_model_iters         0\n",
       "importance_est_variance    0\n",
       "hybrid_est_variance        0\n",
       "true_coverage              0\n",
       "restricted_coverage        0\n",
       "top_k                      0\n",
       "top_p                      0\n",
       "min_variance               0\n",
       "min_var_reduction          0\n",
       "num_beams                  0\n",
       "interp_func                0\n",
       "hist_len                   0\n",
       "total_seq_len              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a52b7fd-4659-494d-9ff3-13584d46e421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('shakespeare_17-18_20.csv',index=None)\n",
    "df.to_csv('moocs_12-13_15.csv',index=None)\n",
    "# df3.to_csv('apps_12-13_15.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ea7d4da0-609f-40e6-ad58-0c5d761c8463",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_dict = read_pkl(\"/srv/disk00/samshow/amazon/amazon_text_dict.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fb6f3eab-1f61-4c3e-bf7c-2ff76eb144c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = amazon_dict['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "19594098-def2-47ac-8f3a-059d760179fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([63844580, 16])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f0b0cc01-7d4b-4203-88ea-d367dd1d10cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0., 16., 16., 16., 11.,  3., 27., 27.,  9.,  9.,  9., 23., 16., 16.,\n",
       "        16.,  8.])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "94c73676-c082-46a2-997d-1cea95e17256",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63844580/63844580 [17:23<00:00, 61164.82it/s]  \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "trans = []\n",
    "for i in tqdm(range(data.shape[0])):\n",
    "    trans.append(torch.unique_consecutive(data[i,1:]).shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6b36271e-5d00-43d2-af28-de548ec74856",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = torch.LongTensor(trans).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c83ae82d-e144-4f7b-9fa1-855591a0f8c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([63844580])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "36efdf43-a1a5-43b0-97c4-9f85633c5f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_pkl(trans, \"/srv/disask00/samshow/amazon/amazon_phase_trans.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "60ad3b21-6ab1-4788-af46-5b60a4823228",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_vals = []\n",
    "for i in range(1,trans.max()+1):\n",
    "    trans_vals.append((trans == i).sum().item()/trans.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "299b9ef8-a587-479e-821d-6b244e68101d",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_perc_per_phase_shift = [0.059163910233257073,\n",
    " 0.020707521296247856,\n",
    " 0.056485656260876024,\n",
    " 0.04778584180520884,\n",
    " 0.07297364944682853,\n",
    " 0.07653857226408256,\n",
    " 0.09382401763783238,\n",
    " 0.10168632952084578,\n",
    " 0.1102257544806466,\n",
    " 0.10986890351538063,\n",
    " 0.09992870185691566,\n",
    " 0.0774158276238954,\n",
    " 0.047934671979986396,\n",
    " 0.020711280425057224,\n",
    " 0.004749361652939059]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e726ba0a-3b52-4c66-93bd-57bbea35dc76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "nlpenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
