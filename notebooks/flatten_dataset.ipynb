{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab5fc0db-8671-45eb-9006-8236cda57d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "import glob\n",
    "import torch\n",
    "\n",
    "sys.path.insert(1,\"/home/showalte/research/prob_seq_queries/\")\n",
    "from seq_queries.utils import read_pkl, write_pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b52721a-1c0f-4001-b451-3899e8e6176e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_experiment_data(experiment, dataset, h, s, root=\"../data\", \n",
    "            methods=['beam_search_is_hybrid','importance_sampling'],\n",
    "            gt_methods=['ground_truth','beam_search']):\n",
    "    \n",
    "        data_dict = {}\n",
    "        gt_type=None\n",
    "        for method in methods:\n",
    "            template_path=root + f\"/{method}/{dataset}/{experiment}/\"\n",
    "            template_file=f\"{experiment.replace('_','-')}_{dataset.replace('_','-')}_{method.replace('_','-')}_{h}h_{s}s*.pkl\"\n",
    "            pot_pattern = os.path.join(template_path,template_file)\n",
    "            pot_paths = glob.glob(pot_pattern)\n",
    "            assert len(pot_paths) == 1,\\\n",
    "                f\"Found {len(pot_paths)} paths for {pot_pattern}\"\n",
    "            data_dict[method]= read_pkl(pot_paths[0])\n",
    "            data_dict[method]['metadata']['result_filepath'] = pot_paths[0]\n",
    "        for gt_method in gt_methods:\n",
    "            try:\n",
    "                template_path=root + f\"/{gt_method}/{dataset}/{experiment}/\"\n",
    "                template_file=f\"{experiment.replace('_','-')}_{dataset.replace('_','-')}_{gt_method.replace('_','-')}_{h}h_{s}s*.pkl\"\n",
    "                pot_pattern = os.path.join(template_path,template_file)\n",
    "                pot_paths = glob.glob(pot_pattern)\n",
    "                assert len(pot_paths) == 1,\\\n",
    "                    f\"Found {len(pot_paths)} paths for {pot_pattern}\"\n",
    "                print(pot_paths[0])\n",
    "                data_dict[gt_method]= read_pkl(pot_paths[0])\n",
    "                data_dict[gt_method]['metadata']['result_filepath'] = pot_paths[0]\n",
    "                data_dict['gt_type'] = gt_method\n",
    "                return data_dict\n",
    "            except: pass\n",
    "        assert False,\"Could not find ground truth\"\n",
    "        return None\n",
    "                \n",
    "            \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae87bf22-bcf6-49ea-b43c-9c6bd34216f9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Estimate fields\n",
    "- ground_truth/beam_search_lb\n",
    "- Importance sampling estimate\n",
    "- Hybrid estimate\n",
    "- Importance sampling variance\n",
    "- Hybrid variance\n",
    "\n",
    "# General Metadata\n",
    "- dataset_name\n",
    "- experiment_name\n",
    "- history_id\n",
    "- Excluded term\n",
    "- sequence_length\n",
    "- history_length\n",
    "- total_sequence_length\n",
    "\n",
    "# Sampling metadata\n",
    "- num_mc_samples (sub_estimates)\n",
    "- sample_model_iters\n",
    "\n",
    "# Hybrid data\n",
    "- hybrid_model_iters\n",
    "\n",
    "# Beam search metadata\n",
    "- min_variance\n",
    "- search_model_iters\n",
    "- min_variance_reduction\n",
    "- true_coverage\n",
    "- restricted_coverage\n",
    "- num_beams\n",
    "- top_k\n",
    "- top_p\n",
    "- (beam search) interpolation_func\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bff8c61a-43ae-4901-8cf0-1f34078701f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def flatten_hybrid_sampling(samp_dict,sub_estimates,sample_type=\"importance\"):\n",
    "#     samp_estimates = samp_dict['hybrid_bs_is_estimate'][:,:len(sub_estimates)]\n",
    "#     if not sub_estimates:\n",
    "#         if len(samp_estimates.shape) ==3:\n",
    "#             assert samp_estimates.shape[1] == samp_dict['metadata']['num_mc_samples'],\\\n",
    "#             (f\"Error, estimate dimensions are {samp_estimates.shape} but the number of samples is\" +\n",
    "#              f\"{samp_dict['metadata']['num_mc_samples']}, which does not match\")\n",
    "            \n",
    "#             samp_estimates = torch.gather(samp_estimates.mean(dim=1),1,\n",
    "#                                           samp_dict['excluded_terms'].unsqueeze(-1)).squeeze()\n",
    "#             assert len(samp_estimates.shape) == 1,f\"Shape of imp_samp_estimates is {len(samp_estimates.shape)}\"\n",
    "#         if len(samp_estimates.shape) ==2:\n",
    "#             samp_estimates = torch.gather(samp_estimates,1,\n",
    "#                                               samp_dict['excluded_terms'].unsqueeze(-1)).squeeze()\n",
    "        \n",
    "#         df = pd.DataFrame(samp_estimates)\n",
    "#         df.insert(0,'num_mc_samples',samp_dict['metadata']['num_mc_samples'])\n",
    "#         df[f'{sample_type}_model_iters'] = samp_dict['model_iters']\n",
    "#         df[f'{sample_type}_est_variance'] = samp_dist['hyrbid_var']\n",
    "        \n",
    "#     else:\n",
    "#         assert samp_estimates.shape[1] == len(sub_estimates),\\\n",
    "#         (\"Importance sampling estimates and sub_estimates are not aligned in shape.\" +\n",
    "#          f\"got sample_est: {samp_estimates.shape[1]} and sub_estimates: {len(sub_estimates)}\")\n",
    "#         print(samp_estimates.shape)\n",
    "#         if len(samp_estimates.shape) == 2:\n",
    "#             samp_estimates = pd.DataFrame(samp_estimates,columns=sub_estimates)\n",
    "#             samp_var = pd.DataFrame(samp_dict['hybrid_var'][:,:len(sub_estimates)],columns=sub_estimates)\n",
    "#             model_iters_df = pd.DataFrame(samp_dict['model_iters'][:,:len(sub_estimates)],columns=sub_estimates)\n",
    "#             df = pd.melt(samp_estimates,value_vars=sub_estimates)\n",
    "#             df.columns = ['num_samples','sample_estimate']\n",
    "#             print(df.head())\n",
    "#             var_df =  pd.melt(samp_var,value_vars=sub_estimates)\n",
    "#             var_df.columns = ['num_samples','variance']\n",
    "#             iter_df = pd.melt(model_iters_df,value_vars=sub_estimates)\n",
    "#             iter_df.columns = ['num_samples','model_iters']\n",
    "#             df[f'{sample_type}_model_iters']=iter_df['model_iters']\n",
    "#             df[f'{sample_type}_est_variance']=var_df['variance']\n",
    "#             print(\"length 2\")\n",
    "#             print(df.shape)\n",
    "            \n",
    "#         elif len(samp_estimates.shape) == 3:\n",
    "#             df_list = []\n",
    "#             for i in range(len(sub_estimates)):\n",
    "#                 df = pd.DataFrame(\n",
    "#                             torch.gather(samp_estimates[:,i],1,\n",
    "#                                       samp_dict['excluded_terms'].unsqueeze(-1)).squeeze()\n",
    "#                         )\n",
    "#                 df.insert(0,'num_mc_samples',sub_estimates[i])\n",
    "#                 df[f'{sample_type}_model_iters'] = samp_dict['model_iters'][:,i]\n",
    "#                 df[f'{sample_type}_est_variance'] = samp_dict['sample_est_var'][:,i]\n",
    "#                 print(df.shape)\n",
    "#                 df_list.append(df)\n",
    "            \n",
    "#             df = pd.concat(df_list,axis=0,ignore_index=True)\n",
    "#         else:\n",
    "#             assert False,f\"Shape of samp_estimates is {len(samp_estimates.shape)}\"\n",
    "#     assert df.shape[-1] == 4, f\"DF shape is {df.shape}\"\n",
    "#     df.columns = ['num_mc_samples',f'{sample_type}_sampling_est',\n",
    "#                   f'{sample_type}_model_iters',f'{sample_type}_est_variance']\n",
    "    \n",
    "#     return df\n",
    "\n",
    "\n",
    "def flatten_sampling(samp_dict,sub_estimates,sample_type=\"importance\"):\n",
    "    samp_estimates = samp_dict['sample_estimates'][:,:len(sub_estimates)]\n",
    "    if not sub_estimates:\n",
    "        if len(samp_estimates.shape) ==3:\n",
    "            assert samp_estimates.shape[1] == samp_dict['metadata']['num_mc_samples'],\\\n",
    "            (f\"Error, estimate dimensions are {samp_estimates.shape} but the number of samples is\" +\n",
    "             f\"{samp_dict['metadata']['num_mc_samples']}, which does not match\")\n",
    "            \n",
    "            samp_estimates = torch.gather(samp_estimates.mean(dim=1),1,\n",
    "                                          samp_dict['excluded_terms'].unsqueeze(-1)).squeeze()\n",
    "            assert len(samp_estimates.shape) == 1,f\"Shape of imp_samp_estimates is {len(samp_estimates.shape)}\"\n",
    "        if len(samp_estimates.shape) ==2:\n",
    "            samp_estimates = torch.gather(samp_estimates,1,\n",
    "                                              samp_dict['excluded_terms'].unsqueeze(-1)).squeeze()\n",
    "        \n",
    "        df = pd.DataFrame(samp_estimates)\n",
    "        df.insert(0,'num_mc_samples',samp_dict['metadata']['num_mc_samples'])\n",
    "        df[f'{sample_type}_model_iters'] = samp_dict['model_iters']\n",
    "        df[f'{sample_type}_est_variance'] = samp_dist['sample_estimate_var']\n",
    "        \n",
    "    else:\n",
    "        assert samp_estimates.shape[1] == len(sub_estimates),\\\n",
    "        (\"Importance sampling estimates and sub_estimates are not aligned in shape.\" +\n",
    "         f\"got sample_est: {samp_estimates.shape[1]} and sub_estimates: {len(sub_estimates)}\")\n",
    "        if len(samp_estimates.shape) == 2:\n",
    "            samp_estimates = pd.DataFrame(samp_estimates,columns=sub_estimates)\n",
    "            samp_var = pd.DataFrame(samp_dict['sample_estimate_var'][:,:len(sub_estimates)],columns=sub_estimates)\n",
    "            model_iters_df = pd.DataFrame(samp_dict['model_iters'][:,:len(sub_estimates)],columns=sub_estimates)\n",
    "            df = pd.melt(samp_estimates,value_vars=sub_estimates)\n",
    "            df.columns = ['num_samples','sample_estimate']\n",
    "            var_df =  pd.melt(samp_var,value_vars=sub_estimates)\n",
    "            var_df.columns = ['num_samples','variance']\n",
    "            iter_df = pd.melt(model_iters_df,value_vars=sub_estimates)\n",
    "            iter_df.columns = ['num_samples','model_iters']\n",
    "            df[f'{sample_type}_model_iters']=iter_df['model_iters']\n",
    "            df[f'{sample_type}_est_variance']=var_df['variance']\n",
    "            \n",
    "        elif len(samp_estimates.shape) == 3:\n",
    "            df_list = []\n",
    "            for i in range(len(sub_estimates)):\n",
    "                df = pd.DataFrame(\n",
    "                            torch.gather(samp_estimates[:,i],1,\n",
    "                                      samp_dict['excluded_terms'].unsqueeze(-1)).squeeze()\n",
    "                        )\n",
    "                df.insert(0,'num_mc_samples',sub_estimates[i])\n",
    "                df[f'{sample_type}_model_iters'] = samp_dict['model_iters'][:,i]\n",
    "                samp_est_var = torch.gather(samp_dict['sample_estimate_var'][:,i],1,\n",
    "                                            samp_dict['excluded_terms'].unsqueeze(-1)).squeeze()\n",
    "                                            \n",
    "                df[f'{sample_type}_est_variance'] = samp_est_var\n",
    "                df_list.append(df)\n",
    "            df = pd.concat(df_list,axis=0,ignore_index=True)\n",
    "        else:\n",
    "            assert False,f\"Shape of samp_estimates is {len(samp_estimates.shape)}\"\n",
    "    assert df.shape[-1] == 4, f\"DF shape is {df.shape}\"\n",
    "    df.columns = ['num_mc_samples',f'{sample_type}_sampling_est',\n",
    "                  f'{sample_type}_model_iters',f'{sample_type}_est_variance']\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def flatten_gt(data_dict,gt_type):\n",
    "    gt_dict = data_dict[gt_type]\n",
    "    # gt = gt_dict['bs_lower_bound']\n",
    "    gt = torch.gather(gt_dict['bs_lower_bound'],1,\n",
    "                      gt_dict['excluded_terms'].unsqueeze(-1)).squeeze()\n",
    "    assert len(gt.shape) == 1,\\\n",
    "    f\"Ground truth has {len(gt.shape)} dimensions\"\n",
    "    df = pd.DataFrame(gt,columns=['ground_truth'])\n",
    "    for item in ['true_coverage','restricted_coverage']:\n",
    "        df[item] = [gti.item() for gti in gt_dict[item]]\n",
    "    # df[\"gt_model_iters\"] = gt_dict['model_iters']\n",
    "    df['gt_type'] = gt_type\n",
    "    \n",
    "    return df\n",
    "    \n",
    "\n",
    "def flatten_experiment(data_dict,experiment, dataset,h,s,\n",
    "     global_agreement_vals= ['excluded_terms']):\n",
    "    sub_estimates = sorted(list(\n",
    "        set(data_dict['importance_sampling']['metadata']['sub_estimates']) &\n",
    "        set(data_dict['beam_search_is_hybrid']['metadata']['sub_estimates'])))\n",
    "    sub_est_len = 1 if not sub_estimates else len(sub_estimates)\n",
    "    importance_df = flatten_sampling(data_dict['importance_sampling'],sub_estimates,sample_type ='importance')\n",
    "    hybrid_df = flatten_sampling(data_dict['beam_search_is_hybrid'],sub_estimates,sample_type ='hybrid')\n",
    "    hybrid_df.drop(\"num_mc_samples\",inplace = True,axis=1)\n",
    "    gt_df = flatten_gt(data_dict,data_dict['gt_type'])\n",
    "    gt_df = pd.concat([gt_df]*sub_est_len,axis=0,ignore_index=True)\n",
    "    final_df = pd.concat([importance_df,hybrid_df,gt_df],axis=1)\n",
    "    # print(hybrid_df.head())\n",
    "    # print(importance_df.head())\n",
    "    # print(final_df.isnull().sum())\n",
    "    \n",
    "    # Metadata checks\n",
    "    is_metadata = ['top_k','top_p']\n",
    "    bs_metadata = ['min_variance','min_var_reduction','num_beams']\n",
    "    for m in is_metadata:\n",
    "        final_df[m] = data_dict['importance_sampling']['metadata'][m]\n",
    "    for m in bs_metadata:\n",
    "        final_df[m] = data_dict[data_dict['gt_type']]['metadata'][m]\n",
    "    final_df['interp_func'] = str(data_dict[data_dict['gt_type']]['metadata']['interp_func']).split(\" \")[1]\n",
    "    \n",
    "    \n",
    "    final_df['dataset_name'] = dataset\n",
    "    final_df['hist_len'] = h\n",
    "    final_df['total_seq_len'] = s\n",
    "    final_df['seq_len'] = s-h\n",
    "    sequence_ids = list(range(data_dict['importance_sampling']['sample_estimates'].shape[0]))*sub_est_len\n",
    "    excluded_terms = data_dict['importance_sampling']['excluded_terms'].numpy().tolist()*sub_est_len\n",
    "    final_df['sequence_id'] = sequence_ids\n",
    "    final_df['excluded_term'] = excluded_terms\n",
    "    phase_shifts = read_pkl(\"/srv/disk00/samshow/amazon/amazon_phase_trans.pkl\")\n",
    "    phase_shift_val_inds = read_pkl(\"../data/amazon/amazon_val_dl_transition_inds.pkl\")\n",
    "    phase_shifts = phase_shifts[phase_shift_val_inds].numpy().tolist()\n",
    "    # print(phase_shift_val_inds.shape, final_df.shape)\n",
    "    # final_df['phase_shifts'] = phase_shifts * sub_est_len\n",
    "    # final_df['phase_shifts'] -=1\n",
    "    \n",
    "    return final_df\n",
    "     \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb936c89-eb0e-42cd-923b-8a60a9fc167c",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = [\"val_dl\"]\n",
    "dataset = [\"apps\"]\n",
    "lengths = [(13,15),(12,15)]\n",
    "def flatten_experiments(experiments, datasets, lengths):\n",
    "    data_list = []\n",
    "    for experiment in experiments:\n",
    "        for dataset in datasets:\n",
    "            for h,s in lengths:\n",
    "                # try:\n",
    "                    \n",
    "                    data = get_experiment_data(experiment,dataset,h,s)\n",
    "                    df = flatten_experiment(data,experiment, dataset, h,s)\n",
    "                    # print(df.head())\n",
    "                    # print(df.columns)\n",
    "                    # print(df.shape)\n",
    "                    # sys.exit(1)\n",
    "                    data_list.append(df)\n",
    "                # except Exception as e:\n",
    "                #     print(\"Could not flatten: Experiment: {} | Dataset: {} | lengths: {}\"\\\n",
    "                #           .format(experiment, dataset, (h,s)))\n",
    "                    \n",
    "    # print(len(data_list))\n",
    "    data_df = pd.concat(data_list,axis = 0)\n",
    "    ordering = [ 'dataset_name','sequence_id','seq_len', 'excluded_term', 'gt_type','ground_truth','importance_sampling_est','hybrid_sampling_est', \n",
    "                'num_mc_samples', 'importance_model_iters','hybrid_model_iters',\n",
    "       'importance_est_variance',  'hybrid_est_variance',\n",
    "         'true_coverage', 'restricted_coverage',  'top_k', 'top_p', 'min_variance',\n",
    "       'min_var_reduction', 'num_beams', 'interp_func',\n",
    "       'hist_len', 'total_seq_len']#, 'phase_shifts']\n",
    "    data_df = data_df[ordering]\n",
    "    print(data_df.columns)\n",
    "    \n",
    "    return data_df\n",
    "                \n",
    "                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62c51bbf-1517-42cc-8ed2-b99b496d041f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/ground_truth/apps/val_dl/val-dl_apps_ground-truth_13h_15s.pkl\n",
      "Index(['dataset_name', 'sequence_id', 'seq_len', 'excluded_term', 'gt_type',\n",
      "       'ground_truth', 'importance_sampling_est', 'hybrid_sampling_est',\n",
      "       'num_mc_samples', 'importance_model_iters', 'hybrid_model_iters',\n",
      "       'importance_est_variance', 'hybrid_est_variance', 'true_coverage',\n",
      "       'restricted_coverage', 'top_k', 'top_p', 'min_variance',\n",
      "       'min_var_reduction', 'num_beams', 'interp_func', 'hist_len',\n",
      "       'total_seq_len'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = flatten_experiments(['val_dl'],['apps'],[(13,15)])\n",
    "# df = flatten_experiments(['val_dl'],['shakespeare'],[(18,20)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ce843b1-19fd-4a08-bd5e-a76576456916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['importance_sampling']['metadata']['sub_estimates']\n",
    "# print(df.shape)\n",
    "# print(df.isnull().sum())\n",
    "# df.phase_shifts.describe()\n",
    "# df[['importance_model_iters','hybrid_model_iters']].tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b010b1e-e070-4f9b-85bf-141fd935acab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'importance')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df = df[df['phase_shifts'] > 10]\n",
    "plt.scatter(df['ground_truth'],df['importance_sampling_est'])\n",
    "plt.title(\"importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a3e8a10-b1b5-4498-bc4a-90eaa5ecbba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance_est_variance</th>\n",
       "      <th>hybrid_est_variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.095900e+04</td>\n",
       "      <td>1.095900e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.887879e-05</td>\n",
       "      <td>4.234356e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.872824e-04</td>\n",
       "      <td>9.936954e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.789122e-19</td>\n",
       "      <td>2.573412e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.158459e-09</td>\n",
       "      <td>1.394701e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.471187e-08</td>\n",
       "      <td>2.084027e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.236981e-07</td>\n",
       "      <td>1.284237e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.537837e-02</td>\n",
       "      <td>4.038442e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       importance_est_variance  hybrid_est_variance\n",
       "count             1.095900e+04         1.095900e+04\n",
       "mean              2.887879e-05         4.234356e-06\n",
       "std               3.872824e-04         9.936954e-05\n",
       "min               7.789122e-19         2.573412e-19\n",
       "25%               5.158459e-09         1.394701e-09\n",
       "50%               4.471187e-08         2.084027e-08\n",
       "75%               3.236981e-07         1.284237e-07\n",
       "max               1.537837e-02         4.038442e-03"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['importance_est_variance','hybrid_est_variance']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ed16f5a-8501-46b6-8e3e-3d4f3a55b259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset_name               0\n",
       "sequence_id                0\n",
       "seq_len                    0\n",
       "excluded_term              0\n",
       "gt_type                    0\n",
       "ground_truth               0\n",
       "importance_sampling_est    0\n",
       "hybrid_sampling_est        0\n",
       "num_mc_samples             0\n",
       "importance_model_iters     0\n",
       "hybrid_model_iters         0\n",
       "importance_est_variance    0\n",
       "hybrid_est_variance        0\n",
       "true_coverage              0\n",
       "restricted_coverage        0\n",
       "top_k                      0\n",
       "top_p                      0\n",
       "min_variance               0\n",
       "min_var_reduction          0\n",
       "num_beams                  0\n",
       "interp_func                0\n",
       "hist_len                   0\n",
       "total_seq_len              0\n",
       "phase_shifts               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a52b7fd-4659-494d-9ff3-13584d46e421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('padhraic_shakespeare_17-18_20.csv',index=None)\n",
    "df.to_csv('amazon_12-13_15_with-phase.csv',index=None)\n",
    "# df.to_csv('padhraic_apps_12-13_15.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ea7d4da0-609f-40e6-ad58-0c5d761c8463",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_dict = read_pkl(\"/srv/disk00/samshow/amazon/amazon_text_dict.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fb6f3eab-1f61-4c3e-bf7c-2ff76eb144c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = amazon_dict['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "19594098-def2-47ac-8f3a-059d760179fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([63844580, 16])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f0b0cc01-7d4b-4203-88ea-d367dd1d10cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0., 16., 16., 16., 11.,  3., 27., 27.,  9.,  9.,  9., 23., 16., 16.,\n",
       "        16.,  8.])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "94c73676-c082-46a2-997d-1cea95e17256",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63844580/63844580 [17:23<00:00, 61164.82it/s]  \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "trans = []\n",
    "for i in tqdm(range(data.shape[0])):\n",
    "    trans.append(torch.unique_consecutive(data[i,1:]).shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6b36271e-5d00-43d2-af28-de548ec74856",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = torch.LongTensor(trans).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c83ae82d-e144-4f7b-9fa1-855591a0f8c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([63844580])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "36efdf43-a1a5-43b0-97c4-9f85633c5f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_pkl(trans, \"/srv/disask00/samshow/amazon/amazon_phase_trans.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "60ad3b21-6ab1-4788-af46-5b60a4823228",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_vals = []\n",
    "for i in range(1,trans.max()+1):\n",
    "    trans_vals.append((trans == i).sum().item()/trans.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "299b9ef8-a587-479e-821d-6b244e68101d",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_perc_per_phase_shift = [0.059163910233257073,\n",
    " 0.020707521296247856,\n",
    " 0.056485656260876024,\n",
    " 0.04778584180520884,\n",
    " 0.07297364944682853,\n",
    " 0.07653857226408256,\n",
    " 0.09382401763783238,\n",
    " 0.10168632952084578,\n",
    " 0.1102257544806466,\n",
    " 0.10986890351538063,\n",
    " 0.09992870185691566,\n",
    " 0.0774158276238954,\n",
    " 0.047934671979986396,\n",
    " 0.020711280425057224,\n",
    " 0.004749361652939059]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e726ba0a-3b52-4c66-93bd-57bbea35dc76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "nlpenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
