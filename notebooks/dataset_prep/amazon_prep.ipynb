{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import gzip\n",
    "import _pickle as cPickle\n",
    "import nltk\n",
    "import tqdm as tqdm\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "http://deepyeti.ucsd.edu/jianmo/amazon/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-04-20 11:27:09--  http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/all_csv_files.csv\n",
      "Resolving deepyeti.ucsd.edu (deepyeti.ucsd.edu)... 169.228.63.50\n",
      "Connecting to deepyeti.ucsd.edu (deepyeti.ucsd.edu)|169.228.63.50|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 9726085576 (9.1G) [application/octet-stream]\n",
      "Saving to: ‘all_csv_files.csv’\n",
      "\n",
      "all_csv_files.csv   100%[===================>]   9.06G  61.9MB/s    in 4m 6s   \n",
      "\n",
      "2022-04-20 11:31:15 (37.7 MB/s) - ‘all_csv_files.csv’ saved [9726085576/9726085576]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !wget http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/all_csv_files.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'overall': 2.0, 'verified': False, 'reviewTime': '12 5, 2015', 'reviewerID': 'A3KUPJ396OQF78', 'asin': 'B017O9P72A', 'summary': 'Buggy', 'unixReviewTime': 1449273600}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "def check_then_delete(item,d):\n",
    "    if item in d:\n",
    "        del d[item]\n",
    "        \n",
    "def getReviewDF(path):\n",
    "    i = 0\n",
    "    df = []\n",
    "    for d in tqdm(parse(path)):\n",
    "            \n",
    "        check_then_delete('reviewText',d)\n",
    "        check_then_delete('reviewerName',d)\n",
    "        check_then_delete('helpful',d)\n",
    "        print(d)\n",
    "        break\n",
    "        if 'description' in d:\n",
    "            del d['description']\n",
    "        if 'image' in d:\n",
    "            del d['image']\n",
    "        if len(d['category']) > 5:\n",
    "            d['category'] = d['category'][:5]\n",
    "        categories = cat_df.get('category',[])\n",
    "        d['category'] = categories[0] if len(categories) > 0 else \"unknown\"\n",
    "        df.append(d)\n",
    "            \n",
    "        i += 1\n",
    "    return df\n",
    "\n",
    "cat_dict = getReviewDF('data/amazon_core5-reviews.json.gz')\n",
    "with open(\"data/amazon_core_5_reviews.pkl\",'wb') as file:\n",
    "    pkl.dump(cat_dict,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {\n",
    "#   \"reviewerID\": \"A2SUAM1J3GNN3B\",\n",
    "#   \"asin\": \"0000013714\",\n",
    "#   \"reviewerName\": \"J. McDonald\",\n",
    "#   \"helpful\": [2, 3],\n",
    "#   \"reviewText\": \"I bought this for my husband who plays the piano.  He is having a wonderful time playing these old hymns.  The music  is at times hard to read because we think the book was published for singing from more than playing from.  Great purchase though!\",\n",
    "#   \"overall\": 5.0,\n",
    "#   \"summary\": \"Heavenly Highway Hymns\",\n",
    "#   \"unixReviewTime\": 1252800000,\n",
    "#   \"reviewTime\": \"09 13, 2009\"\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import gzip\n",
    "\n",
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield json.loads(l)\n",
    "\n",
    "def getMetadataDF(path):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in tqdm(parse(path)):\n",
    "            \n",
    "        # try:\n",
    "        if 'date' in d:\n",
    "            del d['date']\n",
    "        if 'feature' in d:\n",
    "            del d['feature']\n",
    "        if 'description' in d:\n",
    "            del d['description']\n",
    "        if 'image' in d:\n",
    "            del d['image']\n",
    "        if len(d['category']) > 5:\n",
    "            d['category'] = d['category'][:5]\n",
    "        df[d['asin']] = d\n",
    "            # if d['asin'] in df:\n",
    "            #     assert d['category'][0] == df[d['asin']],\\\n",
    "            #     \"Current cat: {} | stored cat: {}\"\\\n",
    "            #           .format(df[d['asin']],d['category'][0])\n",
    "        # except Exception as e:\n",
    "        #     print()\n",
    "        #     print(e)\n",
    "        #     break\n",
    "        #     continue\n",
    "        # break\n",
    "        i += 1\n",
    "        # print(\"========\"*10)\n",
    "        # if i>5:\n",
    "        #     break\n",
    "    return df\n",
    "\n",
    "# cat_dict = getDF('data/amazon_metadata.json.gz')\n",
    "# with open(\"data/amazon_cat_lkp.pkl\",'wb') as file:\n",
    "#     pkl.dump(cat_dict,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open('data/amazon_cat_lkp.pkl','rb') as file:\n",
    "    cat_dict = pkl.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in cat_dict:\n",
    "    cat_dict[key] = cat_dict[key]['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/amazon_reviews.csv',names=[\"user_id\",\"product_id\",\"review\",\"timestamp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae64b44b2c6947a39a4577c00372467e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/233055327 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "df['category'] = df.progress_apply(lambda row: cat_dict[row['product_id']]['category'][0] \n",
    "                     if cat_dict.get(row['product_id'],None) and \n",
    "                              (cat_dict[row['product_id']][0]) > 0 else \"unknown\",axis = 1)\n",
    "df.to_csv(\"data/amazon_rev_with_cat.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = set(list(cat_dict.keys()))\n",
    "lkeys = list(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-39e875e4c9d8>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  testdf.rename(columns={'user_id': 'product_id', 'product_id': 'user_id'}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "testdf.rename(columns={'user_id': 'product_id', 'product_id': 'user_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf = df[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd6aa96a2d0142b0ab8e8d3f8d47cf84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/233055327 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['category'] = df.progress_apply(lambda row: cat_dict[row['product_id']][0] \n",
    "                     if cat_dict.get(row['product_id'],None) and \n",
    "                              len(cat_dict[row['product_id']]) > 0 else \"unknown\",axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/amazon_rev_with_cat.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220183172, 5)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_users = low_users[(low_users.category >= 15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_users.loc['A0001528BGUBOEVR6T5U'].category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_user_set = set(high_users.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_user_set = set(low_users[low_users.category <=15].index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_users = fdf[['user_id','category']].groupby(\"user_id\").count()\n",
    "low_users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# higher_users = \n",
    "with open('data/user_counts.pkl','wb') as file:\n",
    "    pkl.dump(low_users,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "final_fdf = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105622486, 5)\n"
     ]
    }
   ],
   "source": [
    "final_fdf = fdf[~fdf.user_id.isin(low_user_set)]\n",
    "print(final_fdf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_fdf = pd.read_csv(\"data/amazon_rev_with_cat_filtered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_fdf = fdf[fdf.at_least_15_revs == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105622486, 5)\n"
     ]
    }
   ],
   "source": [
    "# fdf = df[df.category != \"unknown\"]\n",
    "# print(fdf.shape)\n",
    "# print(final_fdf.shape)\n",
    "# final_fdf.to_csv(\"data/amazon_rev_with_cat_filtered.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['product_id', 'user_id', 'review', 'timestamp', 'category'], dtype='object')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_fdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_fdf = final_fdf.sort_values(by=['user_id',\n",
    "                        'timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_df,vocab,vocab_dict = prep_amazon_df(final_fdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105622486/105622486 [02:30<00:00, 703091.18it/s]\n"
     ]
    }
   ],
   "source": [
    "seqs = stratify_data_by_user(prep_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2785192/2785192 [02:17<00:00, 20222.04it/s]\n"
     ]
    }
   ],
   "source": [
    "flat_seqs = get_user_sequences(seqs,15, vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_seqs = torch.LongTensor(flat_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = torch.cat((torch.zeros(flat_seqs.shape[0]).unsqueeze(1),flat_seqs),dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict[0] = \"<BOS>\"\n",
    "\n",
    "res = {\"text\":res,\n",
    "       \"vocab\": list(vocab_dict.values()),\n",
    "       \"id_to_char\":vocab_dict,\n",
    "       \"char_to_id\":{v:k for k,v in vocab_dict.items()}\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': tensor([[ 0., 16., 16.,  ..., 16., 16.,  8.],\n",
      "        [ 0., 16., 16.,  ..., 16.,  8.,  8.],\n",
      "        [ 0., 16., 11.,  ...,  8.,  8.,  8.],\n",
      "        ...,\n",
      "        [ 0., 22., 29.,  ...,  8., 29., 24.],\n",
      "        [ 0., 29., 29.,  ..., 29., 24.,  3.],\n",
      "        [ 0., 29., 22.,  ..., 24.,  3.,  2.]]), 'vocab': ['Industrial & Scientific', 'Tools & Home Improvement', 'Patio, Lawn & Garden', 'Arts, Crafts & Sewing', 'Handmade', 'Grocery & Gourmet Food', 'Collectibles & Fine Art', 'Home & Kitchen', 'Automotive', 'Home & Business Services', 'Office Products', 'Musical Instruments', 'Books', 'Appliances', 'Software', 'Electronics', 'Digital Music', 'CDs & Vinyl', 'Video Games', 'Gift Cards', 'Alexa Skills', 'Clothing, Shoes & Jewelry', 'Cell Phones & Accessories', 'Sports & Outdoors', 'Movies & TV', 'Magazine Subscriptions', 'Toys & Games', 'Kindle Store', 'Pet Supplies', '<BOS>'], 'id_to_char': {1: 'Industrial & Scientific', 2: 'Tools & Home Improvement', 3: 'Patio, Lawn & Garden', 4: 'Arts, Crafts & Sewing', 5: 'Handmade', 6: 'Grocery & Gourmet Food', 7: 'Collectibles & Fine Art', 8: 'Home & Kitchen', 9: 'Automotive', 10: 'Home & Business Services', 11: 'Office Products', 12: 'Musical Instruments', 13: 'Books', 14: 'Appliances', 15: 'Software', 16: 'Electronics', 17: 'Digital Music', 18: 'CDs & Vinyl', 19: 'Video Games', 20: 'Gift Cards', 21: 'Alexa Skills', 22: 'Clothing, Shoes & Jewelry', 23: 'Cell Phones & Accessories', 24: 'Sports & Outdoors', 25: 'Movies & TV', 26: 'Magazine Subscriptions', 27: 'Toys & Games', 28: 'Kindle Store', 29: 'Pet Supplies', 0: '<BOS>'}, 'char_to_id': {'Industrial & Scientific': 1, 'Tools & Home Improvement': 2, 'Patio, Lawn & Garden': 3, 'Arts, Crafts & Sewing': 4, 'Handmade': 5, 'Grocery & Gourmet Food': 6, 'Collectibles & Fine Art': 7, 'Home & Kitchen': 8, 'Automotive': 9, 'Home & Business Services': 10, 'Office Products': 11, 'Musical Instruments': 12, 'Books': 13, 'Appliances': 14, 'Software': 15, 'Electronics': 16, 'Digital Music': 17, 'CDs & Vinyl': 18, 'Video Games': 19, 'Gift Cards': 20, 'Alexa Skills': 21, 'Clothing, Shoes & Jewelry': 22, 'Cell Phones & Accessories': 23, 'Sports & Outdoors': 24, 'Movies & TV': 25, 'Magazine Subscriptions': 26, 'Toys & Games': 27, 'Kindle Store': 28, 'Pet Supplies': 29, '<BOS>': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import torch\n",
    "with open(\"data/amazon_text_dict.pkl\",\"wb\") as file:\n",
    "    pkl.dump(res,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_amazon_df(df):\n",
    "    # df = df.sort_values(by=['user_id',\n",
    "    #                     'timestamp'])\n",
    "    vocab = set(df['category'].drop_duplicates().values)\n",
    "    text_dict = {i:c for i,c in zip(range(1,len(vocab)+1,1),vocab)}\n",
    "    text_dict[0] = \"<BOS>\"\n",
    "    return df.loc[:,['user_id','category']].values, vocab, text_dict\n",
    "\n",
    "def stratify_data_by_user(df):\n",
    "    seqs = []; curr_seq = []\n",
    "    curr_user, token = df[0]\n",
    "    curr_seq.append(token)\n",
    "    for i in tqdm.tqdm(range(df.shape[0])):\n",
    "        user,token = df[i]\n",
    "        # New user and new session\n",
    "        if user != curr_user:\n",
    "            curr_user = user\n",
    "            seqs.append(curr_seq)\n",
    "            curr_seq = []\n",
    "        # Just a new session, same user\n",
    "        curr_seq.append(token)\n",
    "\n",
    "    return seqs\n",
    "\n",
    "def get_user_sequences(df_list,\n",
    "                      seq_len,\n",
    "                      text_dict,\n",
    "):\n",
    "    text_dict = {v:k for k,v in text_dict.items()}\n",
    "    flat_seqs = []\n",
    "    for user_data in tqdm.tqdm(df_list):\n",
    "        if len(user_data) < seq_len:\n",
    "            continue\n",
    "        for i in range(seq_len,len(user_data),1):\n",
    "            seq = [text_dict[c] for c in user_data[i-seq_len:i]]\n",
    "            flat_seqs.append(seq)\n",
    "    return flat_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_open.loc[:,'timestamp'] = pd.to_datetime(df_open['timestamp'])\n",
    "df.loc[:,'timestamp'] = pd.to_datetime(df['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "df = df.sort_values(by=['user_id',\n",
    "                        'session_id',\n",
    "                        'timestamp',\n",
    "                        'event_type'])\n",
    "# df.head()\n",
    "print(df.columns)\n",
    "ndf = df.loc[:,['user_id','session_id','app_name']].values\n",
    "# df\n",
    "                    \n",
    "    \n",
    "# df.user_id.drop_duplicates()\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mobile_app_data(data_path):\n",
    "    df = pd.read_csv(data_path, sep='\\t')\n",
    "    df.loc[:,'timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df = df.sort_values(by=['user_id',\n",
    "                        'session_id',\n",
    "                        'timestamp'])\n",
    "    return df.loc[:,['user_id','session_id','app_name']].values\n",
    "\n",
    "def stratify_app_data_by_user(df):\n",
    "    seqs = []; curr_seq = []\n",
    "    curr_user, curr_session, token = df[0]\n",
    "    curr_seq.append(token)\n",
    "    for i in tqdm(range(df.shape[0])):\n",
    "        user, session,token = df[i]\n",
    "        # New user and new session\n",
    "        if user != curr_user:\n",
    "            curr_user = user\n",
    "            seqs.append(curr_seq)\n",
    "            curr_seq = []\n",
    "        # Just a new session, same user\n",
    "        elif session != curr_session:\n",
    "            curr_session = session\n",
    "        curr_seq.append(token)\n",
    "    \n",
    "    return seqs\n",
    "    \n",
    "def get_app_sequences(df_list,\n",
    "                      seq_len,\n",
    "):\n",
    "    flat_seqs = []\n",
    "    for user_data in df_list:\n",
    "        if len(user_data) < seq_len:\n",
    "            continue\n",
    "        for i in range(seq_len,len(user_data),1):\n",
    "            flat_seqs.append(user_data[i-seq_len,i])\n",
    "    return flat_seqs\n",
    "\n",
    "def prepare_mobile_app_data_by_user(\n",
    "    data_path,\n",
    "    seq_len,\n",
    "):\n",
    "    \n",
    "    df = read_mobile_app_data(data_path)\n",
    "    df_list = stratify_app_data_by_user(df)\n",
    "    df_sequences = get_app_sequences(df_list)\n",
    "    return df_sequences\n",
    "    \n",
    "sequences = prepare_mobile_app_data_by_user(ndf)\n",
    "print(sorted([len(s) for s in sequences]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time_dff']  = df[['timestamp']].diff()\n",
    "df['interaction_id'] = (((df.timestamp-df.timestamp.shift(1) > pd.Timedelta(1, 'm')) \n",
    "                              & (df.event_type == 'Opened')) \n",
    "                              | ~(df.app_name == df.app_name.shift(1))\n",
    "                              | ~(df.user_id == df.user_id.shift(1))).cumsum()\n",
    "df['session_id'] = (((df.timestamp-df.timestamp.shift(1) > pd.Timedelta(5, 'm')) \n",
    "                              & (df.event_type == 'Opened')) \n",
    "                              | ~(df.user_id == df.user_id.shift(1))).cumsum()\n",
    "df_start = df.drop_duplicates(subset=['interaction_id'], keep='first')\n",
    "df_end = df.drop_duplicates(subset=['interaction_id'], keep='last')\n",
    "df_start.set_index('interaction_id', inplace=True)\n",
    "df_end.set_index('interaction_id', inplace=True)\n",
    "df_start.loc[:, 'open_time'] = df_start['timestamp']\n",
    "df_start.loc[:, 'close_time']  = df_end['timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_start.groupby('event_type').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "nlpenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
