[2022-04-15 12:10:12.733897] batch_size ........ 1024
[2022-04-15 12:10:12.733916] checkpoint_path ... models/shakespeare/
[2022-04-15 12:10:12.733921] cuda .............. True
[2022-04-15 12:10:12.733925] data_path ......... data/shakespeare_input.txt
[2022-04-15 12:10:12.733928] device_num ........ 7
[2022-04-15 12:10:12.733932] disable_tqdm ...... True
[2022-04-15 12:10:12.733936] do_test ........... False
[2022-04-15 12:10:12.733939] dont_print_args ... False
[2022-04-15 12:10:12.733943] dont_shuffle ...... None
[2022-04-15 12:10:12.733949] dropout ........... 0.3
[2022-04-15 12:10:12.733954] estimate_type ..... <function mc_estimate at 0x7f56f4672700>
[2022-04-15 12:10:12.733958] excluded_terms .... [1]
[2022-04-15 12:10:12.733962] finetune .......... True
[2022-04-15 12:10:12.733966] grad_clip ......... 1.0
[2022-04-15 12:10:12.733969] hidden_size ....... 128
[2022-04-15 12:10:12.733973] hist_len .......... 18
[2022-04-15 12:10:12.733977] interp_func ....... <function lin_interp at 0x7f56f4672820>
[2022-04-15 12:10:12.733980] log_interval ...... 100
[2022-04-15 12:10:12.733984] lr ................ 0.001
[2022-04-15 12:10:12.733989] lr_decay_style .... constant
[2022-04-15 12:10:12.733992] masked_lm ......... False
[2022-04-15 12:10:12.733996] num_beams ......... 0.8
[2022-04-15 12:10:12.733999] num_layers ........ 2
[2022-04-15 12:10:12.734003] num_mc_samples .... 100000
[2022-04-15 12:10:12.734006] num_workers ....... 0
[2022-04-15 12:10:12.734009] optimizer ......... adam
[2022-04-15 12:10:12.734013] proposal_func ..... <function uniform_proposal at 0x7f56f46e3dc0>
[2022-04-15 12:10:12.734016] rnn_type .......... LSTM
[2022-04-15 12:10:12.734020] save_epochs ....... 1
[2022-04-15 12:10:12.734023] seed .............. 1234321
[2022-04-15 12:10:12.734026] seq_len ........... 100
[2022-04-15 12:10:12.734030] shuffle ........... True
[2022-04-15 12:10:12.734033] top_k ............. 0
[2022-04-15 12:10:12.734036] top_p ............. 0
[2022-04-15 12:10:12.734042] total_seq_len ..... 30
[2022-04-15 12:10:12.734045] train_data_pct .... 0.9
[2022-04-15 12:10:12.734049] train_epochs ...... 40
[2022-04-15 12:10:12.734052] val_data_pct ...... 0.05
[2022-04-15 12:10:12.734056] vocab_size ........ 68
[2022-04-15 12:10:12.734060] warmup_pct ........ 0.01
[2022-04-15 12:10:12.734063] weight_decay ...... 0.0
==================================================
{'\n': 0, ' ': 1, '!': 2, '$': 3, '&': 4, "'": 5, ',': 6, '-': 7, '.': 8, '3': 9, ':': 10, ';': 11, '<BOS>': 12, '?': 13, 'A': 14, 'B': 15, 'C': 16, 'D': 17, 'E': 18, 'F': 19, 'G': 20, 'H': 21, 'I': 22, 'J': 23, 'K': 24, 'L': 25, 'M': 26, 'N': 27, 'O': 28, 'P': 29, 'Q': 30, 'R': 31, 'S': 32, 'T': 33, 'U': 34, 'V': 35, 'W': 36, 'X': 37, 'Y': 38, 'Z': 39, '[': 40, ']': 41, 'a': 42, 'b': 43, 'c': 44, 'd': 45, 'e': 46, 'f': 47, 'g': 48, 'h': 49, 'i': 50, 'j': 51, 'k': 52, 'l': 53, 'm': 54, 'n': 55, 'o': 56, 'p': 57, 'q': 58, 'r': 59, 's': 60, 't': 61, 'u': 62, 'v': 63, 'w': 64, 'x': 65, 'y': 66, 'z': 67}
[2022-04-15 12:10:16.214699] Checkpoint path [models/shakespeare/] does exist.
[2022-04-15 12:10:16.217251] Loaded model from models/shakespeare/shakespeare_model.pt
Hist length 25 | Total Seq Length 30 | Num samples: 100000 | Sample type: random

.......................Traceback (most recent call last):
  File "/home/showalte/.conda/envs/nlpenv/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/showalte/.conda/envs/nlpenv/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/showalte/research/prob_seq_queries/scratch.py", line 68, in <module>
    #     estimates = sample_dynamic_target_token(args, val_dl, model)
  File "/home/showalte/.conda/envs/nlpenv/lib/python3.8/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/showalte/research/prob_seq_queries/seq_queries/experiments.py", line 76, in sample_dynamic_target_token
    data_list.append(args.estimate_type(sample,**kwargs))
  File "/home/showalte/.conda/envs/nlpenv/lib/python3.8/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/showalte/research/prob_seq_queries/seq_queries/sample.py", line 94, in mc_estimate
    sample_out = proposal_func(
  File "/home/showalte/research/prob_seq_queries/seq_queries/sample.py", line 43, in uniform_proposal
    output = model.forward(src=torch.cat((hists, samples), dim=-1))  #, device=device)
  File "/home/showalte/research/prob_seq_queries/seq_queries/model.py", line 67, in forward
    rnn_out, misc_out = self.rnn(one_hot_src, rnn_args)
  File "/home/showalte/.conda/envs/nlpenv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/showalte/.conda/envs/nlpenv/lib/python3.8/site-packages/torch/nn/modules/rnn.py", line 761, in forward
    result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
RuntimeError: CUDA out of memory. Tried to allocate 44.00 MiB (GPU 7; 10.76 GiB total capacity; 5.77 GiB already allocated; 12.69 MiB free; 9.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
