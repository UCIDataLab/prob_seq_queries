==================================================
* Running for dataset wikitext
==================================================
354823168
==================================================
[2022-05-17 11:52:32.110334] batch_size ................. 512
[2022-05-17 11:52:32.110372] checkpoint_path ............ None
[2022-05-17 11:52:32.110383] cuda ....................... True
[2022-05-17 11:52:32.110389] data_path .................. data/wikitext/wikitext_val-dl.csv
[2022-05-17 11:52:32.110395] dataset .................... wikitext
[2022-05-17 11:52:32.110400] dataset_phase_shift_path ... /srv/disk00/samshow/amazon/amazon_phase_trans.pkl
[2022-05-17 11:52:32.110406] device ..................... 5
[2022-05-17 11:52:32.110412] device_num ................. 0
[2022-05-17 11:52:32.110418] disable_tqdm ............... True
[2022-05-17 11:52:32.110423] do_test .................... False
[2022-05-17 11:52:32.110430] do_valid ................... True
[2022-05-17 11:52:32.110435] dont_print_args ............ True
[2022-05-17 11:52:32.110440] dont_shuffle ............... None
[2022-05-17 11:52:32.110454] dropout .................... 0.3
[2022-05-17 11:52:32.110463] estimate_type .............. <function beam_search_lower_bound at 0x7f0ee360bdc0>
[2022-05-17 11:52:32.110471] excluded_terms ............. [1]
[2022-05-17 11:52:32.110478] excluded_terms_list ........ [[]]
[2022-05-17 11:52:32.110485] finetune ................... False
[2022-05-17 11:52:32.110491] grad_clip .................. 1.0
[2022-05-17 11:52:32.110497] hidden_size ................ 128
[2022-05-17 11:52:32.110502] hist_len ................... 18
[2022-05-17 11:52:32.110508] hybrid_max_num_beams ....... 1500
[2022-05-17 11:52:32.110516] interp_func ................ <function lin_interp at 0x7f0ee360bca0>
[2022-05-17 11:52:32.110521] log_interval ............... 100
[2022-05-17 11:52:32.110528] lr ......................... 0.001
[2022-05-17 11:52:32.110534] lr_decay_style ............. constant
[2022-05-17 11:52:32.110540] masked_lm .................. False
[2022-05-17 11:52:32.110545] max_k ...................... None
[2022-05-17 11:52:32.110551] max_num_mc_samples ......... 100000
[2022-05-17 11:52:32.110556] max_num_queries ............ 500
[2022-05-17 11:52:32.110562] min_num_mc_samples ......... 10000
[2022-05-17 11:52:32.110567] min_phase_shift ............ 0
[2022-05-17 11:52:32.110573] min_var_reduction .......... 0.1
[2022-05-17 11:52:32.110578] min_variance ............... True
[2022-05-17 11:52:32.110584] model_budget_filepath ...... None
[2022-05-17 11:52:32.110589] needs_dl ................... True
[2022-05-17 11:52:32.110595] num_beams .................. 0.0
[2022-05-17 11:52:32.110600] num_layers ................. 2
[2022-05-17 11:52:32.110606] num_mc_samples ............. 100
[2022-05-17 11:52:32.110611] num_workers ................ 0
[2022-05-17 11:52:32.110616] optimizer .................. adam
[2022-05-17 11:52:32.110622] proposal_func .............. <function lm_proposal at 0x7f0ee35f9ca0>
[2022-05-17 11:52:32.110628] rnn_type ................... LSTM
[2022-05-17 11:52:32.110633] save_epochs ................ 1
[2022-05-17 11:52:32.110639] seed ....................... 42
[2022-05-17 11:52:32.110644] seq_len .................... 20
[2022-05-17 11:52:32.110649] shuffle .................... True
[2022-05-17 11:52:32.110655] store_intermediate_lbs ..... True
[2022-05-17 11:52:32.110661] sub_estimates .............. []
[2022-05-17 11:52:32.110666] tau_a_excl_terms ........... []
[2022-05-17 11:52:32.110672] tau_b_excl_terms ........... []
[2022-05-17 11:52:32.110678] terms_of_interest .......... []
[2022-05-17 11:52:32.110683] text_dict .................. None
[2022-05-17 11:52:32.110689] top_k ...................... 0
[2022-05-17 11:52:32.110694] top_p ...................... 0
[2022-05-17 11:52:32.110699] total_seq_len .............. 20
[2022-05-17 11:52:32.110705] train_data_pct ............. 0.9
[2022-05-17 11:52:32.110710] train_epochs ............... 40
[2022-05-17 11:52:32.110716] use_gpt2 ................... True
[2022-05-17 11:52:32.110721] val_data_pct ............... 0.05
[2022-05-17 11:52:32.110729] val_metrics ................ ['accuracy']
[2022-05-17 11:52:32.110734] valid_epochs ............... 1
[2022-05-17 11:52:32.110742] variance_epsilon ........... 5e-06
[2022-05-17 11:52:32.110748] vocab_size ................. 50257
[2022-05-17 11:52:32.110753] warmup_pct ................. 0.01
[2022-05-17 11:52:32.110759] weight_decay ............... 0.0
==================================================
[2022-05-17 11:52:32.112398] | Dataset: wikitext | Sample type: importance_sampling | Num samples: 1000 | Hist length 11 | Total Seq Length 15 | Pseudo GT: False | Model Budget: True

[2022-05-17 11:52:35.056179] - 0
[2022-05-17 11:52:50.131196] - 1
[2022-05-17 11:53:02.323139] - 2
[2022-05-17 11:53:17.527927] - 3
[2022-05-17 11:53:32.009076] - 4
[2022-05-17 11:53:43.996869] - 5
[2022-05-17 11:53:56.029213] - 6
[2022-05-17 11:54:10.212283] - 7
[2022-05-17 11:54:21.758705] - 8
[2022-05-17 11:54:35.623404] - 9
[2022-05-17 11:54:49.448426] - 10
[2022-05-17 11:55:02.374432] - 11
[2022-05-17 11:55:13.395212] - 12
[2022-05-17 11:55:26.070608] - 13
[2022-05-17 11:55:35.039755] - 14
[2022-05-17 11:55:44.579451] - 15
[2022-05-17 11:55:56.612561] - 16
[2022-05-17 11:56:08.385277] - 17
[2022-05-17 11:56:21.020028] - 18
[2022-05-17 11:56:33.308993] - 19
[2022-05-17 11:56:43.751159] - 20
[2022-05-17 11:56:56.109195] - 21
[2022-05-17 11:57:05.603883] - 22
[2022-05-17 11:57:14.797005] - 23
[2022-05-17 11:57:23.855739] - 24
[2022-05-17 11:57:34.962931] - 25
[2022-05-17 11:57:45.516708] - 26
[2022-05-17 11:57:57.766898] - 27
[2022-05-17 11:58:10.688090] - 28
[2022-05-17 11:58:22.543919] - 29
[2022-05-17 11:58:35.266923] - 30
[2022-05-17 11:58:47.448453] - 31
[2022-05-17 11:58:59.282257] - 32
[2022-05-17 11:59:11.964848] - 33
[2022-05-17 11:59:23.302178] - 34
[2022-05-17 11:59:31.832313] - 35
[2022-05-17 11:59:43.551706] - 36
[2022-05-17 11:59:56.478767] - 37
[2022-05-17 12:00:07.895681] - 38
[2022-05-17 12:00:20.487622] - 39
[2022-05-17 12:00:35.665229] - 40
[2022-05-17 12:00:45.267740] - 41
[2022-05-17 12:00:57.135555] - 42
[2022-05-17 12:01:02.203656] - 43
[2022-05-17 12:01:13.448000] - 44
[2022-05-17 12:01:25.330689] - 45
[2022-05-17 12:01:36.735921] - 46
[2022-05-17 12:01:46.440168] - 47
[2022-05-17 12:01:57.488882] - 48
[2022-05-17 12:02:10.276100] - 49
[2022-05-17 12:02:17.924313] - 50
[2022-05-17 12:02:26.890133] - 51
[2022-05-17 12:02:38.055851] - 52
[2022-05-17 12:02:49.119997] - 53
[2022-05-17 12:03:00.090173] - 54
[2022-05-17 12:03:09.929038] - 55
[2022-05-17 12:03:21.439921] - 56
[2022-05-17 12:03:34.339732] - 57
[2022-05-17 12:03:46.069099] - 58
[2022-05-17 12:03:57.487839] - 59
[2022-05-17 12:04:10.346899] - 60
[2022-05-17 12:04:22.263766] - 61
[2022-05-17 12:04:33.583860] - 62
[2022-05-17 12:04:44.513627] - 63
[2022-05-17 12:04:55.141084] - 64
[2022-05-17 12:05:05.770420] - 65
[2022-05-17 12:05:17.126032] - 66
[2022-05-17 12:05:27.131853] - 67
[2022-05-17 12:05:32.082359] - 68
[2022-05-17 12:05:42.269001] - 69
[2022-05-17 12:05:54.584649] - 70
[2022-05-17 12:06:05.404485] - 71
[2022-05-17 12:06:10.993721] - 72
[2022-05-17 12:06:23.271903] - 73
[2022-05-17 12:06:35.667852] - 74
[2022-05-17 12:06:47.216758] - 75
[2022-05-17 12:06:55.480690] - 76
[2022-05-17 12:07:08.972198] - 77
Traceback (most recent call last):
  File "scripts/get_importance_sampling.py", line 128, in <module>
    estimates = sample_dynamic_target_token(args, val_dl, model)
  File "/home/showalte/.conda/envs/nlpenv/lib/python3.8/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/showalte/research/prob_seq_queries/seq_queries/experiments.py", line 450, in sample_dynamic_target_token
    sample_output =args.estimate_type(sample,**kwargs)
  File "/home/showalte/.conda/envs/nlpenv/lib/python3.8/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/showalte/research/prob_seq_queries/seq_queries/sample.py", line 182, in mc_estimate
    sample_out = proposal_func(
  File "/home/showalte/research/prob_seq_queries/seq_queries/sample.py", line 98, in lm_proposal
    proposal_log_prob += torch.gather(logits, dim=-1, index=last_sample).squeeze(-1)
RuntimeError: output with shape [] doesn't match the broadcast shape [1]
