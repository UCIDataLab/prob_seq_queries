==================================================
* Running for dataset wikitext
==================================================
354823168
==================================================
[2022-05-18 08:10:28.590793] batch_size ................. 512
[2022-05-18 08:10:28.590824] bs_ablation ................ False
[2022-05-18 08:10:28.590829] bs_ablation_max_beams ...... 10000
[2022-05-18 08:10:28.590835] checkpoint_path ............ None
[2022-05-18 08:10:28.590839] cuda ....................... True
[2022-05-18 08:10:28.590843] data_path .................. data/wikitext/wikitext_val-dl.csv
[2022-05-18 08:10:28.590847] dataset .................... wikitext
[2022-05-18 08:10:28.590852] dataset_phase_shift_path ... /srv/disk00/samshow/amazon/amazon_phase_trans.pkl
[2022-05-18 08:10:28.590855] device ..................... 1
[2022-05-18 08:10:28.590859] device_num ................. 0
[2022-05-18 08:10:28.590863] disable_tqdm ............... True
[2022-05-18 08:10:28.590867] do_test .................... False
[2022-05-18 08:10:28.590871] do_valid ................... True
[2022-05-18 08:10:28.590875] dont_print_args ............ True
[2022-05-18 08:10:28.590878] dont_shuffle ............... None
[2022-05-18 08:10:28.590887] dropout .................... 0.3
[2022-05-18 08:10:28.590894] estimate_type .............. <function beam_search_lower_bound at 0x7f1035f95ee0>
[2022-05-18 08:10:28.590902] excluded_terms ............. [1]
[2022-05-18 08:10:28.590907] excluded_terms_list ........ [[]]
[2022-05-18 08:10:28.590911] finetune ................... False
[2022-05-18 08:10:28.590915] grad_clip .................. 1.0
[2022-05-18 08:10:28.590919] hidden_size ................ 128
[2022-05-18 08:10:28.590923] hist_len ................... 18
[2022-05-18 08:10:28.590926] hybrid_max_num_beams ....... 1500
[2022-05-18 08:10:28.590932] interp_func ................ <function lin_interp at 0x7f1035f95dc0>
[2022-05-18 08:10:28.590936] log_interval ............... 100
[2022-05-18 08:10:28.590940] lr ......................... 0.001
[2022-05-18 08:10:28.590944] lr_decay_style ............. constant
[2022-05-18 08:10:28.590947] masked_lm .................. False
[2022-05-18 08:10:28.590951] max_k ...................... None
[2022-05-18 08:10:28.590955] max_num_mc_samples ......... 100000
[2022-05-18 08:10:28.590959] max_num_queries ............ 100
[2022-05-18 08:10:28.590962] min_num_mc_samples ......... 10000
[2022-05-18 08:10:28.590966] min_phase_shift ............ 0
[2022-05-18 08:10:28.590970] min_var_reduction .......... 0.1
[2022-05-18 08:10:28.590973] min_variance ............... True
[2022-05-18 08:10:28.590978] model_budget_filepath ...... None
[2022-05-18 08:10:28.590981] needs_dl ................... True
[2022-05-18 08:10:28.590985] num_beams .................. 0.0
[2022-05-18 08:10:28.590988] num_layers ................. 2
[2022-05-18 08:10:28.590992] num_mc_samples ............. 100
[2022-05-18 08:10:28.590995] num_workers ................ 0
[2022-05-18 08:10:28.590999] optimizer .................. adam
[2022-05-18 08:10:28.591003] proposal_func .............. <function lm_proposal at 0x7f1035f82dc0>
[2022-05-18 08:10:28.591007] rnn_type ................... LSTM
[2022-05-18 08:10:28.591010] save_epochs ................ 1
[2022-05-18 08:10:28.591013] seed ....................... 42
[2022-05-18 08:10:28.591017] seq_len .................... 20
[2022-05-18 08:10:28.591020] shuffle .................... True
[2022-05-18 08:10:28.591024] store_intermediate_lbs ..... True
[2022-05-18 08:10:28.591027] sub_estimates .............. []
[2022-05-18 08:10:28.591031] tau_a_excl_terms ........... []
[2022-05-18 08:10:28.591034] tau_b_excl_terms ........... []
[2022-05-18 08:10:28.591038] terms_of_interest .......... []
[2022-05-18 08:10:28.591041] text_dict .................. None
[2022-05-18 08:10:28.591045] top_k ...................... 0
[2022-05-18 08:10:28.591048] top_p ...................... 0
[2022-05-18 08:10:28.591051] total_seq_len .............. 20
[2022-05-18 08:10:28.591056] train_data_pct ............. 0.9
[2022-05-18 08:10:28.591059] train_epochs ............... 40
[2022-05-18 08:10:28.591062] use_gpt2 ................... True
[2022-05-18 08:10:28.591066] val_data_pct ............... 0.05
[2022-05-18 08:10:28.591072] val_metrics ................ ['accuracy']
[2022-05-18 08:10:28.591075] valid_epochs ............... 1
[2022-05-18 08:10:28.591081] variance_epsilon ........... 5e-06
[2022-05-18 08:10:28.591084] vocab_size ................. 50257
[2022-05-18 08:10:28.591088] warmup_pct ................. 0.01
[2022-05-18 08:10:28.591092] weight_decay ............... 0.0
==================================================
[2022-05-18 08:10:28.591425] | Dataset: wikitext | Sample type: importance_sampling | Num samples: 5000 | Hist length 11 | Total Seq Length 15 | Pseudo GT: False | Model Budget: True

[2022-05-18 08:10:29.047810] - 0
tensor([   31,   260,  2686, 13390])
[2022-05-18 08:11:06.803222] - 1
tensor([   29,   252,  2453, 12343])
[2022-05-18 08:11:44.026402] - 2
tensor([   34,   293,  2918, 14558])
[2022-05-18 08:12:22.975171] - 3
tensor([   34,   293,  2887, 14488])
[2022-05-18 08:13:01.320117] - 4
tensor([   29,   253,  2466, 12255])
[2022-05-18 08:13:37.189672] - 5
tensor([   30,   275,  2764, 13735])
[2022-05-18 08:14:19.396571] - 6
tensor([   33,   300,  2963, 14736])
[2022-05-18 08:15:02.872282] - 7
tensor([   33,   265,  2693, 13505])
[2022-05-18 08:15:43.277326] - 8
tensor([   34,   301,  2974, 14875])
[2022-05-18 08:16:30.012932] - 9
tensor([   32,   293,  2965, 14778])
[2022-05-18 08:17:15.197403] - 10
tensor([   29,   274,  2664, 13261])
[2022-05-18 08:17:57.343933] - 11
tensor([   30,   266,  2614, 13201])
[2022-05-18 08:18:40.377463] - 12
tensor([   34,   302,  2980, 14867])
[2022-05-18 08:19:28.819240] - 13
tensor([   22,   210,  2103, 10418])
[2022-05-18 08:20:04.408012] - 14
tensor([   32,   256,  2426, 12074])
[2022-05-18 08:20:41.009068] - 15
tensor([   33,   299,  2943, 14748])
[2022-05-18 08:21:31.375151] - 16
tensor([   28,   252,  2457, 12303])
[2022-05-18 08:22:24.599996] - 17
tensor([   33,   276,  2752, 13776])
[2022-05-18 08:23:25.219315] - 18
tensor([   33,   295,  2880, 14299])
[2022-05-18 08:24:29.745565] - 19
tensor([   32,   275,  2771, 13920])
[2022-05-18 08:25:31.473202] - 20
tensor([   34,   299,  2946, 14713])
[2022-05-18 08:26:41.121223] - 21
tensor([   24,   203,  2230, 10907])
[2022-05-18 08:27:35.351242] - 22
tensor([   19,   208,  2152, 10956])
[2022-05-18 08:28:29.793693] - 23
tensor([   25,   214,  2076, 10416])
[2022-05-18 08:29:24.100488] - 24
tensor([   29,   281,  2799, 14033])
[2022-05-18 08:30:30.858253] - 25
tensor([   32,   284,  2771, 13853])
[2022-05-18 08:31:37.282548] - 26
tensor([   22,   226,  2383, 12018])
[2022-05-18 08:32:37.267457] - 27
tensor([   31,   295,  2936, 14537])
[2022-05-18 08:33:52.250436] - 28
tensor([   31,   271,  2753, 13758])
[2022-05-18 08:35:01.325604] - 29
tensor([   30,   281,  2797, 13971])
[2022-05-18 08:36:13.706088] - 30
tensor([   33,   294,  2904, 14482])
[2022-05-18 08:37:25.431010] - 31
tensor([   29,   272,  2725, 13605])
[2022-05-18 08:38:35.796139] - 32
tensor([   33,   284,  2796, 14001])
[2022-05-18 08:39:49.523407] - 33
tensor([   32,   267,  2417, 12043])
[2022-05-18 08:40:50.246759] - 34
tensor([   30,   236,  2383, 11799])
[2022-05-18 08:41:53.600536] - 35
tensor([   33,   298,  2931, 14661])
[2022-05-18 08:43:29.830167] - 36
tensor([   34,   294,  2857, 14257])
[2022-05-18 08:44:49.551439] - 37
tensor([   31,   289,  2833, 14173])
[2022-05-18 08:46:08.068725] - 38
tensor([   32,   292,  2834, 14224])
[2022-05-18 08:47:27.316126] - 39
tensor([   34,   302,  2979, 14849])
[2022-05-18 08:48:47.204556] - 40
tensor([   30,   258,  2562, 12855])
[2022-05-18 08:49:47.940005] - 41
tensor([   34,   300,  2956, 14766])
[2022-05-18 08:50:57.203665] - 42
tensor([  22,  150, 1474, 7354])
[2022-05-18 08:51:31.441291] - 43
tensor([   32,   280,  2705, 13554])
[2022-05-18 08:52:32.515835] - 44
tensor([   34,   287,  2843, 14062])
[2022-05-18 08:53:36.998900] - 45
tensor([   34,   294,  2870, 14307])
[2022-05-18 08:54:45.189447] - 46
tensor([   29,   228,  2248, 11165])
[2022-05-18 08:55:38.432995] - 47
tensor([   19,   222,  2291, 11507])
[2022-05-18 08:56:30.416980] - 48
tensor([   32,   281,  2806, 13956])
[2022-05-18 08:57:33.587430] - 49
tensor([  15,  153, 1597, 7986])
[2022-05-18 08:58:12.617100] - 50
tensor([   26,   213,  2207, 11009])
[2022-05-18 08:59:05.884114] - 51
tensor([   32,   285,  2861, 14296])
[2022-05-18 09:00:09.075821] - 52
tensor([   31,   295,  2879, 14434])
[2022-05-18 09:01:14.334153] - 53
tensor([   34,   303,  2993, 14942])
[2022-05-18 09:02:22.877365] - 54
tensor([   32,   279,  2715, 13697])
[2022-05-18 09:03:28.274018] - 55
tensor([   34,   302,  2946, 14690])
[2022-05-18 09:04:35.586008] - 56
tensor([   33,   293,  2886, 14393])
[2022-05-18 09:05:39.863009] - 57
tensor([   33,   281,  2791, 13867])
[2022-05-18 09:06:47.171749] - 58
tensor([   28,   260,  2552, 12785])
[2022-05-18 09:07:46.530979] - 59
tensor([   32,   292,  2898, 14482])
[2022-05-18 09:08:54.150428] - 60
tensor([   33,   286,  2869, 14276])
[2022-05-18 09:09:59.746443] - 61
tensor([   34,   300,  2931, 14658])
[2022-05-18 09:11:07.284936] - 62
tensor([   34,   274,  2658, 13492])
[2022-05-18 09:12:12.486166] - 63
tensor([   25,   219,  2253, 11194])
[2022-05-18 09:13:08.626909] - 64
tensor([   29,   270,  2570, 12624])
[2022-05-18 09:14:12.904667] - 65
tensor([   33,   299,  2904, 14369])
[2022-05-18 09:15:22.219817] - 66
tensor([   28,   245,  2299, 11593])
[2022-05-18 09:16:11.749603] - 67
tensor([  22,  139, 1325, 6646])
[2022-05-18 09:16:40.309609] - 68
tensor([   29,   247,  2437, 12224])
[2022-05-18 09:17:30.490933] - 69
tensor([   34,   290,  2883, 14531])
[2022-05-18 09:18:31.089524] - 70
tensor([   32,   272,  2723, 13715])
[2022-05-18 09:19:29.846750] - 71
tensor([  23,  166, 1628, 7937])
[2022-05-18 09:20:02.442693] - 72
tensor([   31,   289,  2895, 14358])
[2022-05-18 09:20:58.972947] - 73
tensor([   31,   270,  2706, 13574])
[2022-05-18 09:21:56.298863] - 74
tensor([   26,   255,  2496, 12448])
[2022-05-18 09:22:48.644341] - 75
tensor([  24,  199, 1938, 9640])
[2022-05-18 09:23:29.885359] - 76
tensor([   31,   272,  2720, 13574])
[2022-05-18 09:24:27.283709] - 77
tensor([   24,   205,  2028, 10145])
[2022-05-18 09:25:14.335788] - 78
tensor([   34,   304,  2982, 14859])
[2022-05-18 09:26:15.704267] - 79
tensor([   34,   291,  2839, 14191])
[2022-05-18 09:27:18.642063] - 80
tensor([  20,  169, 1732, 8524])
[2022-05-18 09:27:58.425088] - 81
tensor([   34,   296,  2947, 14712])
[2022-05-18 09:29:07.300021] - 82
tensor([   33,   295,  2848, 14195])
[2022-05-18 09:30:15.756369] - 83
tensor([   34,   303,  2972, 14866])
[2022-05-18 09:31:29.912130] - 84
tensor([   34,   302,  2975, 14838])
[2022-05-18 09:32:43.144221] - 85
tensor([   28,   249,  2527, 12577])
[2022-05-18 09:33:38.791090] - 86
tensor([   34,   280,  2766, 13948])
[2022-05-18 09:34:26.279713] - 87
tensor([   26,   230,  2472, 12499])
[2022-05-18 09:35:29.119961] - 88
tensor([   34,   294,  2904, 14490])
[2022-05-18 09:36:47.235318] - 89
tensor([   34,   288,  2728, 13579])
[2022-05-18 09:37:54.963786] - 90
tensor([   31,   283,  2726, 13692])
[2022-05-18 09:39:04.454519] - 91
tensor([   34,   301,  2974, 14843])
[2022-05-18 09:40:15.909651] - 92
tensor([  22,  191, 1934, 9659])
[2022-05-18 09:41:02.139335] - 93
tensor([   33,   283,  2786, 13837])
[2022-05-18 09:42:08.635672] - 94
tensor([  24,  204, 1985, 9979])
[2022-05-18 09:42:54.525042] - 95
tensor([   30,   261,  2663, 13356])
[2022-05-18 09:43:54.207010] - 96
tensor([   33,   288,  2883, 14436])
[2022-05-18 09:45:03.483775] - 97
tensor([   31,   264,  2547, 12693])
[2022-05-18 09:46:06.263855] - 98
tensor([   27,   224,  2200, 10844])
[2022-05-18 09:46:55.069475] - 99
tensor([   30,   279,  2745, 13737])

==================================================
